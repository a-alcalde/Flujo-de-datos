{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Práctica: Flujos de Datos en Clasificación, Concept Drift, Agrupamiento, Anomalías, Texto y Ensembles**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Carga de Datos**\n",
    "\n",
    "Cargamos el dataset que contiene los SMS con sus características extraídas y una columna que indica si es SPAM o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['spam', 'text', 'num_caracteres', 'num_palabras', 'num_alfabeticos',\n",
       "       'num_numericos', 'num_no_alfanum', 'num_divisas', 'num_mayusculas',\n",
       "       'num_exclamaciones', 'num_interrogaciones', 'num_urls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos\n",
    "df = pd.read_csv('spam_SMS_ampliado.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "      <th>num_caracteres</th>\n",
       "      <th>num_palabras</th>\n",
       "      <th>num_alfabeticos</th>\n",
       "      <th>num_numericos</th>\n",
       "      <th>num_no_alfanum</th>\n",
       "      <th>num_divisas</th>\n",
       "      <th>num_mayusculas</th>\n",
       "      <th>num_exclamaciones</th>\n",
       "      <th>num_interrogaciones</th>\n",
       "      <th>num_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>20</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>28</td>\n",
       "      <td>97</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spam                                               text  num_caracteres  \\\n",
       "0     0  Go until jurong point, crazy.. Available only ...             111   \n",
       "1     0                      Ok lar... Joking wif u oni...              29   \n",
       "2     1  Free entry in 2 a wkly comp to win FA Cup fina...             155   \n",
       "3     0  U dun say so early hor... U c already then say...              49   \n",
       "4     0  Nah I don't think he goes to usf, he lives aro...              61   \n",
       "\n",
       "   num_palabras  num_alfabeticos  num_numericos  num_no_alfanum  num_divisas  \\\n",
       "0            20               83              0              28            0   \n",
       "1             6               18              0              11            0   \n",
       "2            28               97             25              33            0   \n",
       "3            11               33              0              16            0   \n",
       "4            13               47              0              14            0   \n",
       "\n",
       "   num_mayusculas  num_exclamaciones  num_interrogaciones  num_urls  \n",
       "0               3                  0                    0         0  \n",
       "1               2                  0                    0         0  \n",
       "2              10                  0                    0         0  \n",
       "3               2                  0                    0         0  \n",
       "4               2                  0                    0         0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Clasificación**\n",
    "\n",
    "Vamos a entrenar y evaluar varios clasificadores online (en flujo de datos):\n",
    "- Árbol Hoeffding (`HoeffdingTreeClassifier`).\n",
    "- Árbol Adaptativo Hoeffding (`HoeffdingAdaptiveTreeClassifier`).\n",
    "- Árbol de Decisión Extremadamente Rápido (`ExtremelyFastDecisionTreeClassifier`).\n",
    "\n",
    "Evaluaremos cada uno utilizando la métrica F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score para HoeffdingTreeClassifier: F1: 86.65%\n"
     ]
    }
   ],
   "source": [
    "from river import tree, metrics\n",
    "\n",
    "model_standard = tree.HoeffdingTreeClassifier()\n",
    "\n",
    "metric = metrics.F1()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "            'num_caracteres': row['num_caracteres'],\n",
    "            'num_palabras': row['num_palabras'],\n",
    "            'num_alfabeticos': row['num_alfabeticos'],\n",
    "            'num_numericos': row['num_numericos'],\n",
    "            'num_no_alfanum': row['num_no_alfanum'],\n",
    "            'num_divisas': row['num_divisas'],\n",
    "            'num_mayusculas': row['num_mayusculas'],\n",
    "            'num_exclamaciones': row['num_exclamaciones'],\n",
    "            'num_interrogaciones': row['num_interrogaciones'],\n",
    "            'num_urls': row['num_urls']\n",
    "        }\n",
    "\n",
    "    y = row['spam'] \n",
    "    y_pred = model_standard.predict_one(x)\n",
    "    model_standard.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "print(f'F1 Score para HoeffdingTreeClassifier: {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score para HoeffdingAdaptiveTreeClassifier: F1: 87.47%\n"
     ]
    }
   ],
   "source": [
    "model_adaptive = tree.HoeffdingAdaptiveTreeClassifier()\n",
    "\n",
    "metric = metrics.F1()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "            'num_caracteres': row['num_caracteres'],\n",
    "            'num_palabras': row['num_palabras'],\n",
    "            'num_alfabeticos': row['num_alfabeticos'],\n",
    "            'num_numericos': row['num_numericos'],\n",
    "            'num_no_alfanum': row['num_no_alfanum'],\n",
    "            'num_divisas': row['num_divisas'],\n",
    "            'num_mayusculas': row['num_mayusculas'],\n",
    "            'num_exclamaciones': row['num_exclamaciones'],\n",
    "            'num_interrogaciones': row['num_interrogaciones'],\n",
    "            'num_urls': row['num_urls']\n",
    "        }\n",
    "\n",
    "    y = row['spam'] \n",
    "    y_pred = model_adaptive.predict_one(x)\n",
    "    model_adaptive.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "print(f'F1 Score para HoeffdingAdaptiveTreeClassifier: {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score para ExtremelyFastDecisionTreeClassifier: F1: 85.23%\n"
     ]
    }
   ],
   "source": [
    "model_extreme = tree.ExtremelyFastDecisionTreeClassifier(grace_period=120)\n",
    "\n",
    "metric = metrics.F1()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "            'num_caracteres': row['num_caracteres'],\n",
    "            'num_palabras': row['num_palabras'],\n",
    "            'num_alfabeticos': row['num_alfabeticos'],\n",
    "            'num_numericos': row['num_numericos'],\n",
    "            'num_no_alfanum': row['num_no_alfanum'],\n",
    "            'num_divisas': row['num_divisas'],\n",
    "            'num_mayusculas': row['num_mayusculas'],\n",
    "            'num_exclamaciones': row['num_exclamaciones'],\n",
    "            'num_interrogaciones': row['num_interrogaciones'],\n",
    "            'num_urls': row['num_urls']\n",
    "        }\n",
    "\n",
    "    y = row['spam'] \n",
    "    y_pred = model_extreme.predict_one(x)\n",
    "    model_extreme.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "\n",
    "print(f'F1 Score para ExtremelyFastDecisionTreeClassifier: {metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Detección de Concept Drift**\n",
    "\n",
    "Para la detección de cambios en el concepto (concept drift), emplearemos varios detectores:\n",
    "- **KSWIN (`KSWIN`)**: Detector de cambios basado en ventanas deslizantes.\n",
    "- **EDDM (`EDDM`)**: Monitor de desviación por error esperado.\n",
    "- **DDM (`DDM`)**: Monitor de desviación por error de detección.\n",
    "\n",
    "Vamos a implementar estos detectores sobre tres modelos distintos:\n",
    "1. HoeffdingTreeClassifier\n",
    "2. HoeffdingAdaptiveTreeClassifier\n",
    "3. ExtremelyFastDecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Concept Drift en HoeffdingTreeClassifier**\n",
    "\n",
    "Entrenaremos un modelo estándar de árbol Hoeffding y usaremos los detectores de concept drift para evaluar si se detectan cambios en los datos durante el flujo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13.0\n",
      "EDDM - Model drift detectado en el ejemplo 48 (F1: 14.29%)\n",
      "EDDM - Model drift detectado en el ejemplo 111 (F1: 16.00%)\n",
      "EDDM - Model drift detectado en el ejemplo 174 (F1: 53.57%)\n",
      "EDDM - Model drift detectado en el ejemplo 224 (F1: 52.46%)\n",
      "EDDM - Model drift detectado en el ejemplo 297 (F1: 59.26%)\n",
      "EDDM - Model drift detectado en el ejemplo 389 (F1: 68.47%)\n",
      "DDM - Model drift detectado en el ejemplo 440 (F1: 71.43%)\n",
      "DDM - Model drift detectado en el ejemplo 471 (F1: 72.73%)\n",
      "EDDM - Model drift detectado en el ejemplo 478 (F1: 73.13%)\n",
      "DDM - Model drift detectado en el ejemplo 502 (F1: 73.91%)\n",
      "EDDM - Model drift detectado en el ejemplo 557 (F1: 75.64%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alvar\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: RuntimeWarning: ks_2samp: Exact calculation unsuccessful. Switching to method=asymp.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KSWIN - Data drift detectado en el ejemplo 2468 (F1: 86.13%)\n",
      "KSWIN - Data drift detectado en el ejemplo 3311 (F1: 85.87%)\n",
      "Resultado final (HoeffdingTreeClassifier): F1: 86.65%\n"
     ]
    }
   ],
   "source": [
    "from river import tree, metrics, drift\n",
    "import river\n",
    "print(river.__version__)\n",
    "\n",
    "model_standard = tree.HoeffdingTreeClassifier()\n",
    "\n",
    "metric = metrics.F1()\n",
    "\n",
    "kswin = drift.KSWIN()\n",
    "eddm = drift.EDDM()\n",
    "ddm = drift.DDM()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "        'num_caracteres': row['num_caracteres'],\n",
    "        'num_palabras': row['num_palabras'],\n",
    "        'num_alfabeticos': row['num_alfabeticos'],\n",
    "        'num_numericos': row['num_numericos'],\n",
    "        'num_no_alfanum': row['num_no_alfanum'],\n",
    "        'num_divisas': row['num_divisas'],\n",
    "        'num_mayusculas': row['num_mayusculas'],\n",
    "        'num_exclamaciones': row['num_exclamaciones'],\n",
    "        'num_interrogaciones': row['num_interrogaciones'],\n",
    "        'num_urls': row['num_urls']\n",
    "    }\n",
    "\n",
    "    y = row['spam'] \n",
    "    y_pred = model_standard.predict_one(x)\n",
    "    model_standard.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "    eddm.update(int(y == y_pred))\n",
    "    ddm.update(int(y == y_pred))\n",
    "    kswin.update(int((x['num_mayusculas'])))\n",
    "    \n",
    "    if eddm.drift_detected: \n",
    "        print(f\"EDDM - Model drift detectado en el ejemplo {index} ({metric})\")\n",
    "    if ddm.drift_detected:\n",
    "        print(f\"DDM - Model drift detectado en el ejemplo {index} ({metric})\")\n",
    "    if kswin.drift_detected:\n",
    "        print(f\"KSWIN - Data drift detectado en el ejemplo {index} ({metric})\")\n",
    "\n",
    "print(f'Resultado final (HoeffdingTreeClassifier): {metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Concept Drift en HoeffdingAdaptiveTreeClassifier**\n",
    "\n",
    "Ahora, vamos a implementar el árbol adaptativo Hoeffding, que puede adaptarse a los cambios detectados en el concepto de los datos, y lo evaluamos con los detectores de drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDDM - Model drift detectado en el ejemplo 45 (F1: 15.38%)\n",
      "EDDM - Model drift detectado en el ejemplo 186 (F1: 60.00%)\n",
      "EDDM - Model drift detectado en el ejemplo 374 (F1: 71.03%)\n",
      "DDM - Model drift detectado en el ejemplo 376 (F1: 71.56%)\n",
      "DDM - Model drift detectado en el ejemplo 407 (F1: 73.04%)\n",
      "KSWIN - Data drift detectado en el ejemplo 2468 (F1: 86.75%)\n",
      "KSWIN - Data drift detectado en el ejemplo 3355 (F1: 85.84%)\n",
      "KSWIN - Data drift detectado en el ejemplo 4054 (F1: 86.47%)\n",
      "Resultado final (HoeffdingAdaptiveTreeClassifier): F1: 86.82%\n"
     ]
    }
   ],
   "source": [
    "# crear, entrenar y evaluar modelo\n",
    "model_adaptive = tree.HoeffdingAdaptiveTreeClassifier()\n",
    "\n",
    "metric = metrics.F1()\n",
    "\n",
    "# detectores de drift\n",
    "kswin = drift.KSWIN()\n",
    "eddm = drift.EDDM()\n",
    "ddm = drift.DDM()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "        'num_caracteres': row['num_caracteres'],\n",
    "        'num_palabras': row['num_palabras'],\n",
    "        'num_alfabeticos': row['num_alfabeticos'],\n",
    "        'num_numericos': row['num_numericos'],\n",
    "        'num_no_alfanum': row['num_no_alfanum'],\n",
    "        'num_divisas': row['num_divisas'],\n",
    "        'num_mayusculas': row['num_mayusculas'],\n",
    "        'num_exclamaciones': row['num_exclamaciones'],\n",
    "        'num_interrogaciones': row['num_interrogaciones'],\n",
    "        'num_urls': row['num_urls']\n",
    "    }\n",
    "\n",
    "    y = row['spam'] \n",
    "    y_pred = model_adaptive.predict_one(x)\n",
    "    model_adaptive.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "    eddm.update(int(y == y_pred))\n",
    "    ddm.update(int(y == y_pred))\n",
    "    kswin.update(int((x['num_mayusculas'])))\n",
    "    \n",
    "    if eddm.drift_detected: \n",
    "        print(f\"EDDM - Model drift detectado en el ejemplo {index} ({metric})\")\n",
    "    if ddm.drift_detected:\n",
    "        print(f\"DDM - Model drift detectado en el ejemplo {index} ({metric})\")\n",
    "    if kswin.drift_detected:\n",
    "        print(f\"KSWIN - Data drift detectado en el ejemplo {index} ({metric})\")\n",
    "\n",
    "print(f'Resultado final (HoeffdingAdaptiveTreeClassifier): {metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Concept Drift en ExtremelyFastDecisionTreeClassifier**\n",
    "\n",
    "Finalmente, probamos el árbol de decisiones extremadamente rápido, junto con los detectores de drift.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDDM - Model drift detectado en el ejemplo 48 (F1: 14.29%)\n",
      "EDDM - Model drift detectado en el ejemplo 111 (F1: 16.00%)\n",
      "EDDM - Model drift detectado en el ejemplo 161 (F1: 50.00%)\n",
      "EDDM - Model drift detectado en el ejemplo 216 (F1: 53.57%)\n",
      "DDM - Model drift detectado en el ejemplo 414 (F1: 69.64%)\n",
      "EDDM - Model drift detectado en el ejemplo 654 (F1: 79.14%)\n",
      "EDDM - Model drift detectado en el ejemplo 845 (F1: 82.17%)\n",
      "EDDM - Model drift detectado en el ejemplo 914 (F1: 83.10%)\n",
      "KSWIN - Data drift detectado en el ejemplo 3347 (F1: 85.12%)\n",
      "KSWIN - Data drift detectado en el ejemplo 3494 (F1: 85.20%)\n",
      "Resultado final (ExtremelyFastDecisionTreeClassifier): F1: 85.23%\n"
     ]
    }
   ],
   "source": [
    "# crear, entrenar y evaluar modelo\n",
    "model_extreme = tree.ExtremelyFastDecisionTreeClassifier(grace_period=120)\n",
    "metric = metrics.F1()\n",
    "\n",
    "# detectores de drift\n",
    "kswin = drift.KSWIN()\n",
    "eddm = drift.EDDM()\n",
    "ddm = drift.DDM()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "        'num_caracteres': row['num_caracteres'],\n",
    "        'num_palabras': row['num_palabras'],\n",
    "        'num_alfabeticos': row['num_alfabeticos'],\n",
    "        'num_numericos': row['num_numericos'],\n",
    "        'num_no_alfanum': row['num_no_alfanum'],\n",
    "        'num_divisas': row['num_divisas'],\n",
    "        'num_mayusculas': row['num_mayusculas'],\n",
    "        'num_exclamaciones': row['num_exclamaciones'],\n",
    "        'num_interrogaciones': row['num_interrogaciones'],\n",
    "        'num_urls': row['num_urls']\n",
    "    }\n",
    "\n",
    "    y = row['spam'] \n",
    "    y_pred = model_extreme.predict_one(x)\n",
    "    model_extreme.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "    eddm.update(int(y == y_pred))\n",
    "    ddm.update(int(y == y_pred))\n",
    "    kswin.update(int((x['num_mayusculas'])))\n",
    "    \n",
    "    if eddm.drift_detected: \n",
    "        print(f\"EDDM - Model drift detectado en el ejemplo {index} ({metric})\")\n",
    "    if ddm.drift_detected:\n",
    "        print(f\"DDM - Model drift detectado en el ejemplo {index} ({metric})\")\n",
    "    if kswin.drift_detected:\n",
    "        print(f\"KSWIN - Data drift detectado en el ejemplo {index} ({metric})\")\n",
    "\n",
    "print(f'Resultado final (ExtremelyFastDecisionTreeClassifier): {metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Agrupamiento y Detección de Anomalías**\n",
    "\n",
    "En esta sección, utilizamos el método no supervisado de KMeans para agrupar los datos en clústeres. Posteriormente, normalizamos los datos y detectamos las anomalías en función de la distancia euclidiana de cada dato al centroide de su clúster asignado.\n",
    "\n",
    "### Pasos:\n",
    "1. Normalizar los datos usando `StandardScaler`.\n",
    "2. Agrupar los datos usando `KMeans` con 5 clústeres.\n",
    "3. Calcular la distancia al centroide del clúster asignado para cada dato.\n",
    "4. Detectar anomalías si la distancia al centroide es mayor a un umbral definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "from river import preprocessing, cluster\n",
    "import math\n",
    "\n",
    "# Crear un escalador para estandarizar los datos\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# Inicializar KMeans con 5 clústeres\n",
    "kmeans = cluster.KMeans(n_clusters=5, seed=42)\n",
    "\n",
    "# Umbral para considerar un punto como anomalía basándonos en la distancia al centroide\n",
    "threshold = 7.0\n",
    "\n",
    "# Para almacenar el conteo de anomalías detectadas\n",
    "anomalies_detected = 0\n",
    "\n",
    "# Función para calcular la distancia euclidiana entre un punto y un centroide\n",
    "def euclidean_distance(point, center):\n",
    "    return math.sqrt(sum((point[feature] - center[feature]) ** 2 for feature in point))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Flujo de Datos para Detección de Anomalías**\n",
    "\n",
    "En esta sección, simulamos el procesamiento en flujo continuo de datos (streaming) y escalamos las características y las agrupamos en clústeres utilizando KMeans. Detectaremos anomalías cuando la distancia al centroide sea mayor que el umbral definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalía detectada en 155 con distancia 7.91\n",
      "Anomalía detectada en 164 con distancia 8.10\n",
      "Anomalía detectada en 188 con distancia 7.53\n",
      "Anomalía detectada en 401 con distancia 7.98\n",
      "Anomalía detectada en 445 con distancia 10.16\n",
      "Anomalía detectada en 455 con distancia 7.47\n",
      "Anomalía detectada en 492 con distancia 7.68\n",
      "Anomalía detectada en 793 con distancia 13.31\n",
      "Anomalía detectada en 838 con distancia 8.99\n",
      "Anomalía detectada en 1036 con distancia 7.09\n",
      "Anomalía detectada en 1085 con distancia 25.62\n",
      "Anomalía detectada en 1385 con distancia 7.57\n",
      "Anomalía detectada en 1463 con distancia 8.08\n",
      "Anomalía detectada en 1487 con distancia 7.12\n",
      "Anomalía detectada en 1546 con distancia 8.04\n",
      "Anomalía detectada en 1579 con distancia 10.47\n",
      "Anomalía detectada en 1586 con distancia 7.78\n",
      "Anomalía detectada en 1609 con distancia 9.89\n",
      "Anomalía detectada en 1659 con distancia 8.96\n",
      "Anomalía detectada en 1793 con distancia 7.29\n",
      "Anomalía detectada en 1827 con distancia 7.81\n",
      "Anomalía detectada en 1863 con distancia 9.58\n",
      "Anomalía detectada en 1876 con distancia 7.57\n",
      "Anomalía detectada en 2010 con distancia 8.35\n",
      "Anomalía detectada en 2014 con distancia 7.30\n",
      "Anomalía detectada en 2144 con distancia 8.50\n",
      "Anomalía detectada en 2158 con distancia 11.74\n",
      "Anomalía detectada en 2300 con distancia 7.21\n",
      "Anomalía detectada en 2356 con distancia 8.22\n",
      "Anomalía detectada en 2503 con distancia 19.65\n",
      "Anomalía detectada en 2619 con distancia 7.32\n",
      "Anomalía detectada en 2674 con distancia 7.88\n",
      "Anomalía detectada en 2676 con distancia 14.59\n",
      "Anomalía detectada en 2681 con distancia 8.71\n",
      "Anomalía detectada en 2791 con distancia 10.40\n",
      "Anomalía detectada en 2849 con distancia 10.41\n",
      "Anomalía detectada en 2905 con distancia 8.23\n",
      "Anomalía detectada en 2933 con distancia 8.76\n",
      "Anomalía detectada en 2946 con distancia 8.09\n",
      "Anomalía detectada en 2960 con distancia 9.90\n",
      "Anomalía detectada en 3059 con distancia 7.40\n",
      "Anomalía detectada en 3174 con distancia 7.67\n",
      "Anomalía detectada en 3316 con distancia 7.80\n",
      "Anomalía detectada en 3443 con distancia 7.71\n",
      "Anomalía detectada en 3454 con distancia 8.57\n",
      "Anomalía detectada en 3564 con distancia 10.27\n",
      "Anomalía detectada en 3668 con distancia 9.62\n",
      "Anomalía detectada en 3679 con distancia 7.06\n",
      "Anomalía detectada en 3738 con distancia 7.17\n",
      "Anomalía detectada en 3939 con distancia 9.84\n",
      "Anomalía detectada en 4154 con distancia 7.88\n",
      "Anomalía detectada en 4206 con distancia 8.18\n",
      "Anomalía detectada en 4299 con distancia 8.18\n",
      "Anomalía detectada en 4312 con distancia 7.76\n",
      "Anomalía detectada en 4318 con distancia 9.29\n",
      "Anomalía detectada en 4399 con distancia 9.86\n",
      "Anomalía detectada en 4450 con distancia 8.24\n",
      "Anomalía detectada en 4529 con distancia 7.83\n",
      "Anomalía detectada en 4574 con distancia 9.12\n",
      "Anomalía detectada en 4836 con distancia 7.14\n",
      "Anomalía detectada en 4867 con distancia 7.77\n",
      "Anomalía detectada en 4905 con distancia 9.77\n",
      "Anomalía detectada en 4911 con distancia 8.97\n",
      "Anomalía detectada en 4948 con distancia 8.10\n",
      "Anomalía detectada en 4994 con distancia 9.76\n",
      "Anomalía detectada en 5004 con distancia 8.72\n",
      "Anomalía detectada en 5019 con distancia 10.54\n",
      "Anomalía detectada en 5083 con distancia 10.15\n",
      "Anomalía detectada en 5106 con distancia 11.96\n",
      "Anomalía detectada en 5266 con distancia 11.11\n",
      "Anomalía detectada en 5268 con distancia 9.75\n",
      "Anomalía detectada en 5402 con distancia 7.77\n",
      "Anomalía detectada en 5454 con distancia 7.31\n",
      "Anomalía detectada en 5542 con distancia 10.11\n",
      "Total de anomalías detectadas: 74\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    features = {\n",
    "        'num_caracteres': float(row['num_caracteres']),\n",
    "        'num_palabras': float(row['num_palabras']),\n",
    "        'num_alfabeticos': float(row['num_alfabeticos']),\n",
    "        'num_numericos': float(row['num_numericos']),\n",
    "        'num_no_alfanum': float(row['num_no_alfanum']),\n",
    "        'num_divisas': float(row['num_divisas']),\n",
    "        'num_mayusculas': float(row['num_mayusculas']),\n",
    "        'num_exclamaciones': float(row['num_exclamaciones']),\n",
    "        'num_interrogaciones': float(row['num_interrogaciones']),\n",
    "        'num_urls': float(row['num_urls'])\n",
    "    }\n",
    "\n",
    "    scaler.learn_one(features)\n",
    "    \n",
    "    features_scaled = scaler.transform_one(features)\n",
    "\n",
    "    cluster_id = kmeans.predict_one(features_scaled)\n",
    "\n",
    "    centroids = kmeans.centers\n",
    "\n",
    "    if centroids:\n",
    "        centroid = centroids[cluster_id]\n",
    "\n",
    "        distance_to_centroid = euclidean_distance(features_scaled, centroid)\n",
    "\n",
    "        if distance_to_centroid > threshold:\n",
    "            anomalies_detected += 1\n",
    "            print(f\"Anomalía detectada en {index} con distancia {distance_to_centroid:.2f}\")\n",
    "\n",
    "    kmeans.learn_one(features_scaled)\n",
    "\n",
    "print(f\"Total de anomalías detectadas: {anomalies_detected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tratamiento de Texto**\n",
    "\n",
    "En esta sección, compararemos dos técnicas para la extracción de características de texto:\n",
    "- **Bag of Words (BOW)**: Simplemente cuenta las ocurrencias de cada palabra en el texto.\n",
    "- **TF-IDF (Term Frequency-Inverse Document Frequency)**: Pondera la frecuencia de las palabras considerando también su relevancia en el conjunto total de datos.\n",
    "\n",
    "Ambas técnicas serán combinadas con un clasificador Naive Bayes para evaluar cuál de las dos consigue mejores resultados en la clasificación de mensajes SPAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bag of Words con Naive Bayes**\n",
    "\n",
    "En este apartado implementamos la técnica de Bag of Words junto con el clasificador Naive Bayes. Entrenaremos el modelo y evaluaremos su rendimiento usando la métrica **F1 Score**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score final con Bag of Words: 0.9002590673575129\n"
     ]
    }
   ],
   "source": [
    "from river import feature_extraction, naive_bayes, compose, metrics\n",
    "\n",
    "bow = feature_extraction.BagOfWords(lowercase=True)\n",
    "\n",
    "model_bayes = naive_bayes.MultinomialNB()\n",
    "\n",
    "pipeline_BowNb = compose.Pipeline(('vectorizer', bow), ('nb', model_bayes))\n",
    "\n",
    "metric = metrics.F1()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    y = row['spam']\n",
    "    \n",
    "    y_pred = pipeline_BowNb.predict_one(text)\n",
    "    \n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "    pipeline_BowNb.learn_one(text, y)\n",
    "\n",
    "print(f\"F1 Score final con Bag of Words: {metric.get()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TF-IDF con Naive Bayes**\n",
    "\n",
    "En esta parte, utilizamos la técnica de TF-IDF junto con el clasificador Naive Bayes. Evaluaremos su rendimiento en flujo de datos de la misma manera que lo hicimos con Bag of Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score final con TF-IDF: 0.7371090448013524\n"
     ]
    }
   ],
   "source": [
    "tfidf = feature_extraction.TFIDF(lowercase=True, ngram_range=(1,1))\n",
    "model_bayes = naive_bayes.MultinomialNB()\n",
    "pipeline_TFIDFNb = compose.Pipeline(('vectorizer', tfidf), ('TFI-IDF', model_bayes))\n",
    "\n",
    "metric = metrics.F1()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    y = row['spam']\n",
    "    \n",
    "    y_pred = pipeline_TFIDFNb.predict_one(text)\n",
    "    \n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "    pipeline_TFIDFNb.learn_one(text, y)\n",
    "\n",
    "print(f\"F1 Score final con TF-IDF: {metric.get()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ensembles (Vacío)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Flujo de datos Simulado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos recibidos: {'text': 'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', 'num_caracteres': 111, 'num_palabras': 20, 'num_alfabeticos': 83, 'num_numericos': 0, 'num_no_alfanum': 28, 'num_divisas': 0, 'num_mayusculas': 3, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Ok lar... Joking wif u oni...', 'num_caracteres': 29, 'num_palabras': 6, 'num_alfabeticos': 18, 'num_numericos': 0, 'num_no_alfanum': 11, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", 'num_caracteres': 155, 'num_palabras': 28, 'num_alfabeticos': 97, 'num_numericos': 25, 'num_no_alfanum': 33, 'num_divisas': 0, 'num_mayusculas': 10, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 1\n",
      "Datos recibidos: {'text': 'U dun say so early hor... U c already then say...', 'num_caracteres': 49, 'num_palabras': 11, 'num_alfabeticos': 33, 'num_numericos': 0, 'num_no_alfanum': 16, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"Nah I don't think he goes to usf, he lives around here though\", 'num_caracteres': 61, 'num_palabras': 13, 'num_alfabeticos': 47, 'num_numericos': 0, 'num_no_alfanum': 14, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\", 'num_caracteres': 147, 'num_palabras': 32, 'num_alfabeticos': 103, 'num_numericos': 4, 'num_no_alfanum': 40, 'num_divisas': 1, 'num_mayusculas': 7, 'num_exclamaciones': 2, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 1\n",
      "Datos recibidos: {'text': 'Even my brother is not like to speak with me. They treat me like aids patent.', 'num_caracteres': 77, 'num_palabras': 16, 'num_alfabeticos': 60, 'num_numericos': 0, 'num_no_alfanum': 17, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\", 'num_caracteres': 160, 'num_palabras': 26, 'num_alfabeticos': 128, 'num_numericos': 1, 'num_no_alfanum': 31, 'num_divisas': 0, 'num_mayusculas': 10, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.', 'num_caracteres': 157, 'num_palabras': 26, 'num_alfabeticos': 106, 'num_numericos': 19, 'num_no_alfanum': 32, 'num_divisas': 1, 'num_mayusculas': 12, 'num_exclamaciones': 3, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 1\n",
      "Datos recibidos: {'text': 'Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030', 'num_caracteres': 154, 'num_palabras': 29, 'num_alfabeticos': 111, 'num_numericos': 13, 'num_no_alfanum': 30, 'num_divisas': 0, 'num_mayusculas': 14, 'num_exclamaciones': 1, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 1\n",
      "Datos recibidos: {'text': \"I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\", 'num_caracteres': 109, 'num_palabras': 21, 'num_alfabeticos': 83, 'num_numericos': 0, 'num_no_alfanum': 26, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info', 'num_caracteres': 136, 'num_palabras': 26, 'num_alfabeticos': 81, 'num_numericos': 22, 'num_no_alfanum': 33, 'num_divisas': 0, 'num_mayusculas': 17, 'num_exclamaciones': 1, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 1\n",
      "Datos recibidos: {'text': 'URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18', 'num_caracteres': 155, 'num_palabras': 26, 'num_alfabeticos': 101, 'num_numericos': 20, 'num_no_alfanum': 34, 'num_divisas': 1, 'num_mayusculas': 40, 'num_exclamaciones': 2, 'num_interrogaciones': 0, 'num_urls': 1}, Etiqueta: 1\n",
      "Datos recibidos: {'text': \"I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\", 'num_caracteres': 196, 'num_palabras': 37, 'num_alfabeticos': 156, 'num_numericos': 0, 'num_no_alfanum': 40, 'num_divisas': 0, 'num_mayusculas': 3, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'I HAVE A DATE ON SUNDAY WITH WILL!!', 'num_caracteres': 35, 'num_palabras': 8, 'num_alfabeticos': 26, 'num_numericos': 0, 'num_no_alfanum': 9, 'num_divisas': 0, 'num_mayusculas': 26, 'num_exclamaciones': 2, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL', 'num_caracteres': 149, 'num_palabras': 19, 'num_alfabeticos': 120, 'num_numericos': 0, 'num_no_alfanum': 29, 'num_divisas': 0, 'num_mayusculas': 23, 'num_exclamaciones': 0, 'num_interrogaciones': 1, 'num_urls': 1}, Etiqueta: 1\n",
      "Datos recibidos: {'text': \"Oh k...i'm watching here:)\", 'num_caracteres': 26, 'num_palabras': 4, 'num_alfabeticos': 17, 'num_numericos': 0, 'num_no_alfanum': 9, 'num_divisas': 0, 'num_mayusculas': 1, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Eh u remember how 2 spell his name... Yes i did. He v naughty make until i v wet.', 'num_caracteres': 81, 'num_palabras': 19, 'num_alfabeticos': 57, 'num_numericos': 1, 'num_no_alfanum': 23, 'num_divisas': 0, 'num_mayusculas': 3, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Fine if that’s the way u feel. That’s the way its gota b', 'num_caracteres': 56, 'num_palabras': 13, 'num_alfabeticos': 41, 'num_numericos': 0, 'num_no_alfanum': 15, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/ú1.20 POBOXox36504W45WQ 16+', 'num_caracteres': 155, 'num_palabras': 24, 'num_alfabeticos': 101, 'num_numericos': 23, 'num_no_alfanum': 31, 'num_divisas': 0, 'num_mayusculas': 32, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 1\n",
      "Datos recibidos: {'text': 'Is that seriously how you spell his name?', 'num_caracteres': 41, 'num_palabras': 8, 'num_alfabeticos': 33, 'num_numericos': 0, 'num_no_alfanum': 8, 'num_divisas': 0, 'num_mayusculas': 1, 'num_exclamaciones': 0, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'I‘m going to try for 2 months ha ha only joking', 'num_caracteres': 47, 'num_palabras': 11, 'num_alfabeticos': 35, 'num_numericos': 1, 'num_no_alfanum': 11, 'num_divisas': 0, 'num_mayusculas': 1, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'So ü pay first lar... Then when is da stock comin...', 'num_caracteres': 52, 'num_palabras': 11, 'num_alfabeticos': 36, 'num_numericos': 0, 'num_no_alfanum': 16, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Aft i finish my lunch then i go str down lor. Ard 3 smth lor. U finish ur lunch already?', 'num_caracteres': 88, 'num_palabras': 20, 'num_alfabeticos': 65, 'num_numericos': 1, 'num_no_alfanum': 22, 'num_divisas': 0, 'num_mayusculas': 3, 'num_exclamaciones': 0, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Ffffffffff. Alright no way I can meet up with you sooner?', 'num_caracteres': 57, 'num_palabras': 11, 'num_alfabeticos': 45, 'num_numericos': 0, 'num_no_alfanum': 12, 'num_divisas': 0, 'num_mayusculas': 3, 'num_exclamaciones': 0, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"Just forced myself to eat a slice. I'm really not hungry tho. This sucks. Mark is getting worried. He knows I'm sick when I turn down pizza. Lol\", 'num_caracteres': 144, 'num_palabras': 28, 'num_alfabeticos': 110, 'num_numericos': 0, 'num_no_alfanum': 34, 'num_divisas': 0, 'num_mayusculas': 8, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Lol your always so convincing.', 'num_caracteres': 30, 'num_palabras': 5, 'num_alfabeticos': 25, 'num_numericos': 0, 'num_no_alfanum': 5, 'num_divisas': 0, 'num_mayusculas': 1, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"Did you catch the bus ? Are you frying an egg ? Did you make a tea? Are you eating your mom's left over dinner ? Do you feel my Love ?\", 'num_caracteres': 134, 'num_palabras': 32, 'num_alfabeticos': 97, 'num_numericos': 0, 'num_no_alfanum': 37, 'num_divisas': 0, 'num_mayusculas': 6, 'num_exclamaciones': 0, 'num_interrogaciones': 5, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"I'm back &amp; we're packing the car now, I'll let you know if there's room\", 'num_caracteres': 75, 'num_palabras': 15, 'num_alfabeticos': 54, 'num_numericos': 0, 'num_no_alfanum': 21, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Ahhh. Work. I vaguely remember that! What does it feel like? Lol', 'num_caracteres': 64, 'num_palabras': 12, 'num_alfabeticos': 49, 'num_numericos': 0, 'num_no_alfanum': 15, 'num_divisas': 0, 'num_mayusculas': 5, 'num_exclamaciones': 1, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"Wait that's still not all that clear, were you not sure about me being sarcastic or that that's why x doesn't want to live with us\", 'num_caracteres': 130, 'num_palabras': 26, 'num_alfabeticos': 101, 'num_numericos': 0, 'num_no_alfanum': 29, 'num_divisas': 0, 'num_mayusculas': 1, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"Yeah he got in at 2 and was v apologetic. n had fallen out and she was actin like spoilt child and he got caught up in that. Till 2! But we won't go there! Not doing too badly cheers. You?\", 'num_caracteres': 188, 'num_palabras': 41, 'num_alfabeticos': 139, 'num_numericos': 2, 'num_no_alfanum': 47, 'num_divisas': 0, 'num_mayusculas': 5, 'num_exclamaciones': 2, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'K tell me anything about you.', 'num_caracteres': 29, 'num_palabras': 6, 'num_alfabeticos': 23, 'num_numericos': 0, 'num_no_alfanum': 6, 'num_divisas': 0, 'num_mayusculas': 1, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'For fear of fainting with the of all that housework you just did? Quick have a cuppa', 'num_caracteres': 84, 'num_palabras': 17, 'num_alfabeticos': 67, 'num_numericos': 0, 'num_no_alfanum': 17, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Thanks for your subscription to Ringtone UK your mobile will be charged £5/month Please confirm by replying YES or NO. If you reply NO you will not be charged', 'num_caracteres': 158, 'num_palabras': 29, 'num_alfabeticos': 126, 'num_numericos': 1, 'num_no_alfanum': 31, 'num_divisas': 1, 'num_mayusculas': 13, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 1\n",
      "Datos recibidos: {'text': 'Yup... Ok i go home look at the timings then i msg ü again... Xuhui going to learn on 2nd may too but her lesson is at 8am', 'num_caracteres': 122, 'num_palabras': 28, 'num_alfabeticos': 87, 'num_numericos': 2, 'num_no_alfanum': 33, 'num_divisas': 0, 'num_mayusculas': 3, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"Oops, I'll let you know when my roommate's done\", 'num_caracteres': 47, 'num_palabras': 9, 'num_alfabeticos': 36, 'num_numericos': 0, 'num_no_alfanum': 11, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'I see the letter B on my car', 'num_caracteres': 28, 'num_palabras': 8, 'num_alfabeticos': 21, 'num_numericos': 0, 'num_no_alfanum': 7, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Anything lor... U decide...', 'num_caracteres': 27, 'num_palabras': 4, 'num_alfabeticos': 18, 'num_numericos': 0, 'num_no_alfanum': 9, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"Hello! How's you and how did saturday go? I was just texting to see if you'd decided to do anything tomo. Not that i'm trying to invite myself or anything!\", 'num_caracteres': 155, 'num_palabras': 30, 'num_alfabeticos': 119, 'num_numericos': 0, 'num_no_alfanum': 36, 'num_divisas': 0, 'num_mayusculas': 4, 'num_exclamaciones': 2, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Pls go ahead with watts. I just wanted to be sure. Do have a great weekend. Abiola', 'num_caracteres': 82, 'num_palabras': 17, 'num_alfabeticos': 63, 'num_numericos': 0, 'num_no_alfanum': 19, 'num_divisas': 0, 'num_mayusculas': 4, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Did I forget to tell you ? I want you , I need you, I crave you ... But most of all ... I love you my sweet Arabian steed ... Mmmmmm ... Yummy', 'num_caracteres': 142, 'num_palabras': 34, 'num_alfabeticos': 94, 'num_numericos': 0, 'num_no_alfanum': 48, 'num_divisas': 0, 'num_mayusculas': 10, 'num_exclamaciones': 0, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': '07732584351 - Rodger Burns - MSG = We tried to call you re your reply to our sms for a free nokia mobile + free camcorder. Please call now 08000930705 for delivery tomorrow', 'num_caracteres': 172, 'num_palabras': 33, 'num_alfabeticos': 113, 'num_numericos': 22, 'num_no_alfanum': 37, 'num_divisas': 0, 'num_mayusculas': 7, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 1\n",
      "Datos recibidos: {'text': 'WHO ARE YOU SEEING?', 'num_caracteres': 19, 'num_palabras': 4, 'num_alfabeticos': 15, 'num_numericos': 0, 'num_no_alfanum': 4, 'num_divisas': 0, 'num_mayusculas': 15, 'num_exclamaciones': 0, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Great! I hope you like your man well endowed. I am  &lt;#&gt;  inches...', 'num_caracteres': 72, 'num_palabras': 13, 'num_alfabeticos': 48, 'num_numericos': 0, 'num_no_alfanum': 24, 'num_divisas': 0, 'num_mayusculas': 3, 'num_exclamaciones': 1, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'No calls..messages..missed calls', 'num_caracteres': 32, 'num_palabras': 3, 'num_alfabeticos': 26, 'num_numericos': 0, 'num_no_alfanum': 6, 'num_divisas': 0, 'num_mayusculas': 1, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"Didn't you get hep b immunisation in nigeria.\", 'num_caracteres': 45, 'num_palabras': 8, 'num_alfabeticos': 36, 'num_numericos': 0, 'num_no_alfanum': 9, 'num_divisas': 0, 'num_mayusculas': 1, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Fair enough, anything going on?', 'num_caracteres': 31, 'num_palabras': 5, 'num_alfabeticos': 25, 'num_numericos': 0, 'num_no_alfanum': 6, 'num_divisas': 0, 'num_mayusculas': 1, 'num_exclamaciones': 0, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"Yeah hopefully, if tyler can't do it I could maybe ask around a bit\", 'num_caracteres': 67, 'num_palabras': 14, 'num_alfabeticos': 52, 'num_numericos': 0, 'num_no_alfanum': 15, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"U don't know how stubborn I am. I didn't even want to go to the hospital. I kept telling Mark I'm not a weak sucker. Hospitals are for weak suckers.\", 'num_caracteres': 148, 'num_palabras': 30, 'num_alfabeticos': 112, 'num_numericos': 0, 'num_no_alfanum': 36, 'num_divisas': 0, 'num_mayusculas': 7, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'What you thinked about me. First time you saw me in class.', 'num_caracteres': 58, 'num_palabras': 12, 'num_alfabeticos': 45, 'num_numericos': 0, 'num_no_alfanum': 13, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'A gram usually runs like  &lt;#&gt; , a half eighth is smarter though and gets you almost a whole second gram for  &lt;#&gt;', 'num_caracteres': 124, 'num_palabras': 23, 'num_alfabeticos': 89, 'num_numericos': 0, 'num_no_alfanum': 35, 'num_divisas': 0, 'num_mayusculas': 1, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"K fyi x has a ride early tomorrow morning but he's crashing at our place tonight\", 'num_caracteres': 80, 'num_palabras': 16, 'num_alfabeticos': 64, 'num_numericos': 0, 'num_no_alfanum': 16, 'num_divisas': 0, 'num_mayusculas': 1, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Wow. I never realized that you were so embarassed by your accomodations. I thought you liked it, since i was doing the best i could and you always seemed so happy about \"the cave\". I\\'m sorry I didn\\'t and don\\'t have more to give. I\\'m sorry i offered. I\\'m sorry your room was so embarassing.', 'num_caracteres': 289, 'num_palabras': 55, 'num_alfabeticos': 221, 'num_numericos': 0, 'num_no_alfanum': 68, 'num_divisas': 0, 'num_mayusculas': 7, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'SMS. ac Sptv: The New Jersey Devils and the Detroit Red Wings play Ice Hockey. Correct or Incorrect? End? Reply END SPTV', 'num_caracteres': 120, 'num_palabras': 22, 'num_alfabeticos': 94, 'num_numericos': 0, 'num_no_alfanum': 26, 'num_divisas': 0, 'num_mayusculas': 24, 'num_exclamaciones': 0, 'num_interrogaciones': 2, 'num_urls': 0}, Etiqueta: 1\n",
      "Datos recibidos: {'text': 'Do you know what Mallika Sherawat did yesterday? Find out now @  &lt;URL&gt;', 'num_caracteres': 76, 'num_palabras': 13, 'num_alfabeticos': 57, 'num_numericos': 0, 'num_no_alfanum': 19, 'num_divisas': 0, 'num_mayusculas': 7, 'num_exclamaciones': 0, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Congrats! 1 year special cinema pass for 2 is yours. call 09061209465 now! C Suprman V, Matrix3, StarWars3, etc all 4 FREE! bx420-ip4-5we. 150pm. Dont miss out!', 'num_caracteres': 160, 'num_palabras': 27, 'num_alfabeticos': 98, 'num_numericos': 24, 'num_no_alfanum': 38, 'num_divisas': 0, 'num_mayusculas': 12, 'num_exclamaciones': 4, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 1\n",
      "Datos recibidos: {'text': \"Sorry, I'll call later in meeting.\", 'num_caracteres': 34, 'num_palabras': 6, 'num_alfabeticos': 26, 'num_numericos': 0, 'num_no_alfanum': 8, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Tell where you reached', 'num_caracteres': 22, 'num_palabras': 4, 'num_alfabeticos': 19, 'num_numericos': 0, 'num_no_alfanum': 3, 'num_divisas': 0, 'num_mayusculas': 1, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Yes..gauti and sehwag out of odi series.', 'num_caracteres': 40, 'num_palabras': 7, 'num_alfabeticos': 31, 'num_numericos': 0, 'num_no_alfanum': 9, 'num_divisas': 0, 'num_mayusculas': 1, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"Your gonna have to pick up a $1 burger for yourself on your way home. I can't even move. Pain is killing me.\", 'num_caracteres': 108, 'num_palabras': 23, 'num_alfabeticos': 80, 'num_numericos': 1, 'num_no_alfanum': 27, 'num_divisas': 1, 'num_mayusculas': 3, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Ha ha ha good joke. Girls are situation seekers.', 'num_caracteres': 48, 'num_palabras': 9, 'num_alfabeticos': 38, 'num_numericos': 0, 'num_no_alfanum': 10, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Its a part of checking IQ', 'num_caracteres': 25, 'num_palabras': 6, 'num_alfabeticos': 20, 'num_numericos': 0, 'num_no_alfanum': 5, 'num_divisas': 0, 'num_mayusculas': 3, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Sorry my roommates took forever, it ok if I come by now?', 'num_caracteres': 56, 'num_palabras': 12, 'num_alfabeticos': 43, 'num_numericos': 0, 'num_no_alfanum': 13, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Ok lar i double check wif da hair dresser already he said wun cut v short. He said will cut until i look nice.', 'num_caracteres': 110, 'num_palabras': 24, 'num_alfabeticos': 85, 'num_numericos': 0, 'num_no_alfanum': 25, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'As a valued customer, I am pleased to advise you that following recent review of your Mob No. you are awarded with a £1500 Bonus Prize, call 09066364589', 'num_caracteres': 152, 'num_palabras': 28, 'num_alfabeticos': 106, 'num_numericos': 15, 'num_no_alfanum': 31, 'num_divisas': 1, 'num_mayusculas': 6, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 1\n",
      "Datos recibidos: {'text': 'Today is \"song dedicated day..\" Which song will u dedicate for me? Send this to all ur valuable frnds but first rply me...', 'num_caracteres': 122, 'num_palabras': 23, 'num_alfabeticos': 92, 'num_numericos': 0, 'num_no_alfanum': 30, 'num_divisas': 0, 'num_mayusculas': 3, 'num_exclamaciones': 0, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Urgent UR awarded a complimentary trip to EuroDisinc Trav, Aco&Entry41 Or £1000. To claim txt DIS to 87121 18+6*£1.50(moreFrmMob. ShrAcomOrSglSuplt)10, LS1 3AJ', 'num_caracteres': 159, 'num_palabras': 22, 'num_alfabeticos': 105, 'num_numericos': 21, 'num_no_alfanum': 33, 'num_divisas': 2, 'num_mayusculas': 24, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 1\n",
      "Datos recibidos: {'text': 'Did you hear about the new \"Divorce Barbie\"? It comes with all of Ken\\'s stuff!', 'num_caracteres': 78, 'num_palabras': 15, 'num_alfabeticos': 59, 'num_numericos': 0, 'num_no_alfanum': 19, 'num_divisas': 0, 'num_mayusculas': 5, 'num_exclamaciones': 1, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 1\n",
      "Datos recibidos: {'text': 'I plane to give on this month end.', 'num_caracteres': 34, 'num_palabras': 8, 'num_alfabeticos': 26, 'num_numericos': 0, 'num_no_alfanum': 8, 'num_divisas': 0, 'num_mayusculas': 1, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Wah lucky man... Then can save money... Hee...', 'num_caracteres': 46, 'num_palabras': 8, 'num_alfabeticos': 30, 'num_numericos': 0, 'num_no_alfanum': 16, 'num_divisas': 0, 'num_mayusculas': 3, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Finished class where are you.', 'num_caracteres': 29, 'num_palabras': 5, 'num_alfabeticos': 24, 'num_numericos': 0, 'num_no_alfanum': 5, 'num_divisas': 0, 'num_mayusculas': 1, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'HI BABE IM AT HOME NOW WANNA DO SOMETHING? XX', 'num_caracteres': 45, 'num_palabras': 10, 'num_alfabeticos': 35, 'num_numericos': 0, 'num_no_alfanum': 10, 'num_divisas': 0, 'num_mayusculas': 35, 'num_exclamaciones': 0, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'K..k:)where are you?how did you performed?', 'num_caracteres': 42, 'num_palabras': 6, 'num_alfabeticos': 31, 'num_numericos': 0, 'num_no_alfanum': 11, 'num_divisas': 0, 'num_mayusculas': 1, 'num_exclamaciones': 0, 'num_interrogaciones': 2, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'U can call me now...', 'num_caracteres': 20, 'num_palabras': 5, 'num_alfabeticos': 13, 'num_numericos': 0, 'num_no_alfanum': 7, 'num_divisas': 0, 'num_mayusculas': 1, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'I am waiting machan. Call me once you free.', 'num_caracteres': 43, 'num_palabras': 9, 'num_alfabeticos': 33, 'num_numericos': 0, 'num_no_alfanum': 10, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Proceso detenido por el usuario.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "try:\n",
    "    for index, row in df.iterrows():\n",
    "        X = {\n",
    "            'text': row['text'],\n",
    "            'num_caracteres': row['num_caracteres'],\n",
    "            'num_palabras': row['num_palabras'],\n",
    "            'num_alfabeticos': row['num_alfabeticos'],\n",
    "            'num_numericos': row['num_numericos'],\n",
    "            'num_no_alfanum': row['num_no_alfanum'],\n",
    "            'num_divisas': row['num_divisas'],\n",
    "            'num_mayusculas': row['num_mayusculas'],\n",
    "            'num_exclamaciones': row['num_exclamaciones'],\n",
    "            'num_interrogaciones': row['num_interrogaciones'],\n",
    "            'num_urls': row['num_urls']\n",
    "        }\n",
    "\n",
    "        y = row['spam'] \n",
    "        \n",
    "        print(f\"Datos recibidos: {X}, Etiqueta: {y}\")\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print('Proceso detenido por el usuario.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
