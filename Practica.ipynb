{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Práctica: Flujos de Datos en Clasificación, Concept Drift, Agrupamiento, Anomalías, Texto y Ensembles**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Carga de Datos**\n",
    "\n",
    "Cargamos el dataset que contiene los SMS con sus características extraídas y una columna que indica si es SPAM o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['spam', 'text', 'num_caracteres', 'num_palabras', 'num_alfabeticos',\n",
       "       'num_numericos', 'num_no_alfanum', 'num_divisas', 'num_mayusculas',\n",
       "       'num_exclamaciones', 'num_interrogaciones', 'num_urls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos\n",
    "df = pd.read_csv('spam_SMS_ampliado.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "      <th>num_caracteres</th>\n",
       "      <th>num_palabras</th>\n",
       "      <th>num_alfabeticos</th>\n",
       "      <th>num_numericos</th>\n",
       "      <th>num_no_alfanum</th>\n",
       "      <th>num_divisas</th>\n",
       "      <th>num_mayusculas</th>\n",
       "      <th>num_exclamaciones</th>\n",
       "      <th>num_interrogaciones</th>\n",
       "      <th>num_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>20</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>28</td>\n",
       "      <td>97</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spam                                               text  num_caracteres  \\\n",
       "0     0  Go until jurong point, crazy.. Available only ...             111   \n",
       "1     0                      Ok lar... Joking wif u oni...              29   \n",
       "2     1  Free entry in 2 a wkly comp to win FA Cup fina...             155   \n",
       "3     0  U dun say so early hor... U c already then say...              49   \n",
       "4     0  Nah I don't think he goes to usf, he lives aro...              61   \n",
       "\n",
       "   num_palabras  num_alfabeticos  num_numericos  num_no_alfanum  num_divisas  \\\n",
       "0            20               83              0              28            0   \n",
       "1             6               18              0              11            0   \n",
       "2            28               97             25              33            0   \n",
       "3            11               33              0              16            0   \n",
       "4            13               47              0              14            0   \n",
       "\n",
       "   num_mayusculas  num_exclamaciones  num_interrogaciones  num_urls  \n",
       "0               3                  0                    0         0  \n",
       "1               2                  0                    0         0  \n",
       "2              10                  0                    0         0  \n",
       "3               2                  0                    0         0  \n",
       "4               2                  0                    0         0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Clasificación**\n",
    "\n",
    "Vamos a entrenar y evaluar varios clasificadores online (en flujo de datos):\n",
    "- Árbol Hoeffding (`HoeffdingTreeClassifier`).\n",
    "- Árbol Adaptativo Hoeffding (`HoeffdingAdaptiveTreeClassifier`).\n",
    "- Árbol de Decisión Extremadamente Rápido (`ExtremelyFastDecisionTreeClassifier`).\n",
    "\n",
    "Estos tres modelos utilizan árboles de decisión para realizar la clasificación junto con el teorema de Hoeffding, el primero lo hemos elegido porque debería dar buenos resultados al estar tratando con un flujo de datos estable, sin embargo, queremos ver que efecto tiene el AdaptiveHoeffdingTree ya que este modelo tiene la capacidad de adaptarse al concept drift, por la estructura de nuestros datos, creemos que no hay mucho concept drift, sin embargo, pensamos que siempre puede haber un poco por lo que creemos que aplicando el árbol adaptativo podremos mejorar los resultados respecto al estándar, ya que, en caso de que haya una ligera desviación en las características de los datos, el modelo pueda detectarlo y adaptarse a ello.\n",
    "Por último hemos querido probar el árbol extremadamente rápido, para ver como afecta la optimización de este modelo frente al modelo estable en los resultados, teniendo en mente que el resultado podría empeorar.\n",
    " \n",
    "Evaluaremos cada uno utilizando la métrica F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score para HoeffdingTreeClassifier: F1: 86.65%\n"
     ]
    }
   ],
   "source": [
    "from river import tree, metrics\n",
    "\n",
    "model_standard = tree.HoeffdingTreeClassifier()\n",
    "\n",
    "metric = metrics.F1()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "            'num_caracteres': row['num_caracteres'],\n",
    "            'num_palabras': row['num_palabras'],\n",
    "            'num_alfabeticos': row['num_alfabeticos'],\n",
    "            'num_numericos': row['num_numericos'],\n",
    "            'num_no_alfanum': row['num_no_alfanum'],\n",
    "            'num_divisas': row['num_divisas'],\n",
    "            'num_mayusculas': row['num_mayusculas'],\n",
    "            'num_exclamaciones': row['num_exclamaciones'],\n",
    "            'num_interrogaciones': row['num_interrogaciones'],\n",
    "            'num_urls': row['num_urls']\n",
    "        }\n",
    "\n",
    "    y = row['spam'] \n",
    "    y_pred = model_standard.predict_one(x)\n",
    "    model_standard.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "print(f'F1 Score para HoeffdingTreeClassifier: {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score para HoeffdingAdaptiveTreeClassifier: F1: 86.85%\n"
     ]
    }
   ],
   "source": [
    "model_adaptive = tree.HoeffdingAdaptiveTreeClassifier()\n",
    "\n",
    "metric = metrics.F1()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "            'num_caracteres': row['num_caracteres'],\n",
    "            'num_palabras': row['num_palabras'],\n",
    "            'num_alfabeticos': row['num_alfabeticos'],\n",
    "            'num_numericos': row['num_numericos'],\n",
    "            'num_no_alfanum': row['num_no_alfanum'],\n",
    "            'num_divisas': row['num_divisas'],\n",
    "            'num_mayusculas': row['num_mayusculas'],\n",
    "            'num_exclamaciones': row['num_exclamaciones'],\n",
    "            'num_interrogaciones': row['num_interrogaciones'],\n",
    "            'num_urls': row['num_urls']\n",
    "        }\n",
    "\n",
    "    y = row['spam'] \n",
    "    y_pred = model_adaptive.predict_one(x)\n",
    "    model_adaptive.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "print(f'F1 Score para HoeffdingAdaptiveTreeClassifier: {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score para ExtremelyFastDecisionTreeClassifier: F1: 86.16%\n"
     ]
    }
   ],
   "source": [
    "model_extreme = tree.ExtremelyFastDecisionTreeClassifier(grace_period=120)\n",
    "\n",
    "metric = metrics.F1()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "            'num_caracteres': row['num_caracteres'],\n",
    "            'num_palabras': row['num_palabras'],\n",
    "            'num_alfabeticos': row['num_alfabeticos'],\n",
    "            'num_numericos': row['num_numericos'],\n",
    "            'num_no_alfanum': row['num_no_alfanum'],\n",
    "            'num_divisas': row['num_divisas'],\n",
    "            'num_mayusculas': row['num_mayusculas'],\n",
    "            'num_exclamaciones': row['num_exclamaciones'],\n",
    "            'num_interrogaciones': row['num_interrogaciones'],\n",
    "            'num_urls': row['num_urls']\n",
    "        }\n",
    "\n",
    "    y = row['spam'] \n",
    "    y_pred = model_extreme.predict_one(x)\n",
    "    model_extreme.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "\n",
    "print(f'F1 Score para ExtremelyFastDecisionTreeClassifier: {metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como era de esperar la precisión medida por el F1-Score es menor en el árbol extremadamente rápido, aunque esta disminución en el resultado es muy ligera, lo que nos lleva a pensar que en una implantación real en la que nuestra detección de Spam en SMSs tiene que ser lo más rápido posible debido a la forma en la que entran los datos, lo consideramos una buena opción para implementaciones en tiempo real.\n",
    "Además, hemos visto como el árbol adaptativo es efectivamente, más preciso que el estándar, gracias a su capacidad de adaptarse al concept drift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Detección de Concept Drift**\n",
    "\n",
    "Tras clasificar correctamente los datos y ver cómo el árbol adaptativo se ha adaptado al concept drift (ya que ha mejorado sus predicciones frente a las del árbol estándar), pasamos a la detección de este concept drift, para ello utilizaremos los siguientes detectores, tanto de data drift como de model drift:\n",
    "\n",
    "- **KSWIN (`KSWIN`)**: Detector de cambios basado en ventanas deslizantes.\n",
    "- **EDDM (`EDDM`)**: Monitor de desviación por error esperado.\n",
    "- **DDM (`DDM`)**: Monitor de desviación por error de detección.\n",
    "\n",
    "Vamos a implementar estos detectores sobre los tres modelos iniciales:\n",
    "1. HoeffdingTreeClassifier\n",
    "2. HoeffdingAdaptiveTreeClassifier\n",
    "3. ExtremelyFastDecisionTreeClassifier\n",
    "\n",
    "La idea de probarlos en los tres modelos es sobre todo para comparar el número de detecciones que ocurren entre el modelo estándar y el extremadamente rápido frente al adaptativo, que, según creemos debería detectar menos cambios ya que se va adaptando a ellos durante la clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Concept Drift en HoeffdingTreeClassifier**\n",
    "\n",
    "Entrenaremos un modelo estándar de árbol Hoeffding y usaremos los detectores de concept drift para evaluar si se detectan cambios en los datos durante el flujo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.2\n",
      "EDDM - Model drift detectado en el ejemplo 48 (F1: 14.29%)\n",
      "EDDM - Model drift detectado en el ejemplo 111 (F1: 16.00%)\n",
      "EDDM - Model drift detectado en el ejemplo 174 (F1: 53.57%)\n",
      "EDDM - Model drift detectado en el ejemplo 224 (F1: 52.46%)\n",
      "EDDM - Model drift detectado en el ejemplo 297 (F1: 59.26%)\n",
      "EDDM - Model drift detectado en el ejemplo 389 (F1: 68.47%)\n",
      "DDM - Model drift detectado en el ejemplo 440 (F1: 71.43%)\n",
      "EDDM - Model drift detectado en el ejemplo 478 (F1: 73.13%)\n",
      "EDDM - Model drift detectado en el ejemplo 557 (F1: 75.64%)\n",
      "KSWIN - Data drift detectado en el ejemplo 2469 (F1: 86.13%)\n",
      "Resultado final (HoeffdingTreeClassifier): F1: 86.65%\n"
     ]
    }
   ],
   "source": [
    "from river import tree, metrics, drift\n",
    "import river\n",
    "print(river.__version__)\n",
    "\n",
    "model_standard = tree.HoeffdingTreeClassifier()\n",
    "\n",
    "metric = metrics.F1()\n",
    "\n",
    "kswin = drift.KSWIN()\n",
    "eddm = drift.binary.EDDM()\n",
    "ddm = drift.binary.DDM()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "        'num_caracteres': row['num_caracteres'],\n",
    "        'num_palabras': row['num_palabras'],\n",
    "        'num_alfabeticos': row['num_alfabeticos'],\n",
    "        'num_numericos': row['num_numericos'],\n",
    "        'num_no_alfanum': row['num_no_alfanum'],\n",
    "        'num_divisas': row['num_divisas'],\n",
    "        'num_mayusculas': row['num_mayusculas'],\n",
    "        'num_exclamaciones': row['num_exclamaciones'],\n",
    "        'num_interrogaciones': row['num_interrogaciones'],\n",
    "        'num_urls': row['num_urls']\n",
    "    }\n",
    "\n",
    "    y = row['spam'] \n",
    "    y_pred = model_standard.predict_one(x)\n",
    "    model_standard.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "    eddm.update(int(y == y_pred))\n",
    "    ddm.update(int(y == y_pred))\n",
    "    kswin.update(int((x['num_mayusculas'])))\n",
    "    \n",
    "    if eddm.drift_detected: \n",
    "        print(f\"EDDM - Model drift detectado en el ejemplo {index} ({metric})\")\n",
    "    if ddm.drift_detected:\n",
    "        print(f\"DDM - Model drift detectado en el ejemplo {index} ({metric})\")\n",
    "    if kswin.drift_detected:\n",
    "        print(f\"KSWIN - Data drift detectado en el ejemplo {index} ({metric})\")\n",
    "\n",
    "print(f'Resultado final (HoeffdingTreeClassifier): {metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Concept Drift en HoeffdingAdaptiveTreeClassifier**\n",
    "\n",
    "Ahora, vamos a implementar el árbol adaptativo Hoeffding, que puede adaptarse a los cambios detectados en el concepto de los datos, y lo evaluamos con los detectores de drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDDM - Model drift detectado en el ejemplo 51 (F1: 13.33%)\n",
      "EDDM - Model drift detectado en el ejemplo 114 (F1: 33.33%)\n",
      "EDDM - Model drift detectado en el ejemplo 161 (F1: 53.85%)\n",
      "EDDM - Model drift detectado en el ejemplo 216 (F1: 56.67%)\n",
      "DDM - Model drift detectado en el ejemplo 216 (F1: 56.67%)\n",
      "EDDM - Model drift detectado en el ejemplo 304 (F1: 62.50%)\n",
      "EDDM - Model drift detectado en el ejemplo 378 (F1: 69.81%)\n",
      "KSWIN - Data drift detectado en el ejemplo 2044 (F1: 86.88%)\n",
      "KSWIN - Data drift detectado en el ejemplo 3371 (F1: 86.44%)\n",
      "KSWIN - Data drift detectado en el ejemplo 3496 (F1: 86.50%)\n",
      "KSWIN - Data drift detectado en el ejemplo 4622 (F1: 86.97%)\n",
      "Resultado final (HoeffdingAdaptiveTreeClassifier): F1: 87.33%\n"
     ]
    }
   ],
   "source": [
    "# crear, entrenar y evaluar modelo\n",
    "model_adaptive = tree.HoeffdingAdaptiveTreeClassifier()\n",
    "\n",
    "metric = metrics.F1()\n",
    "\n",
    "# detectores de drift\n",
    "kswin = drift.KSWIN()\n",
    "eddm = drift.binary.EDDM()\n",
    "ddm = drift.binary.DDM()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "        'num_caracteres': row['num_caracteres'],\n",
    "        'num_palabras': row['num_palabras'],\n",
    "        'num_alfabeticos': row['num_alfabeticos'],\n",
    "        'num_numericos': row['num_numericos'],\n",
    "        'num_no_alfanum': row['num_no_alfanum'],\n",
    "        'num_divisas': row['num_divisas'],\n",
    "        'num_mayusculas': row['num_mayusculas'],\n",
    "        'num_exclamaciones': row['num_exclamaciones'],\n",
    "        'num_interrogaciones': row['num_interrogaciones'],\n",
    "        'num_urls': row['num_urls']\n",
    "    }\n",
    "\n",
    "    y = row['spam'] \n",
    "    y_pred = model_adaptive.predict_one(x)\n",
    "    model_adaptive.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "    eddm.update(int(y == y_pred))\n",
    "    ddm.update(int(y == y_pred))\n",
    "    kswin.update(int((x['num_mayusculas'])))\n",
    "    \n",
    "    if eddm.drift_detected: \n",
    "        print(f\"EDDM - Model drift detectado en el ejemplo {index} ({metric})\")\n",
    "    if ddm.drift_detected:\n",
    "        print(f\"DDM - Model drift detectado en el ejemplo {index} ({metric})\")\n",
    "    if kswin.drift_detected:\n",
    "        print(f\"KSWIN - Data drift detectado en el ejemplo {index} ({metric})\")\n",
    "\n",
    "print(f'Resultado final (HoeffdingAdaptiveTreeClassifier): {metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Concept Drift en ExtremelyFastDecisionTreeClassifier**\n",
    "\n",
    "Finalmente, probamos el árbol de decisiones extremadamente rápido, junto con los detectores de drift.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDDM - Model drift detectado en el ejemplo 48 (F1: 14.29%)\n",
      "EDDM - Model drift detectado en el ejemplo 111 (F1: 16.00%)\n",
      "EDDM - Model drift detectado en el ejemplo 161 (F1: 50.00%)\n",
      "EDDM - Model drift detectado en el ejemplo 216 (F1: 53.57%)\n",
      "DDM - Model drift detectado en el ejemplo 414 (F1: 69.64%)\n",
      "EDDM - Model drift detectado en el ejemplo 654 (F1: 79.14%)\n",
      "EDDM - Model drift detectado en el ejemplo 845 (F1: 82.17%)\n",
      "EDDM - Model drift detectado en el ejemplo 914 (F1: 83.10%)\n",
      "KSWIN - Data drift detectado en el ejemplo 2465 (F1: 84.45%)\n",
      "KSWIN - Data drift detectado en el ejemplo 3354 (F1: 85.12%)\n",
      "KSWIN - Data drift detectado en el ejemplo 3494 (F1: 85.20%)\n",
      "KSWIN - Data drift detectado en el ejemplo 4619 (F1: 85.11%)\n",
      "Resultado final (ExtremelyFastDecisionTreeClassifier): F1: 86.16%\n"
     ]
    }
   ],
   "source": [
    "# crear, entrenar y evaluar modelo\n",
    "model_extreme = tree.ExtremelyFastDecisionTreeClassifier(grace_period=120)\n",
    "metric = metrics.F1()\n",
    "\n",
    "# detectores de drift\n",
    "kswin = drift.KSWIN()\n",
    "eddm = drift.binary.EDDM()\n",
    "ddm = drift.binary.DDM()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "        'num_caracteres': row['num_caracteres'],\n",
    "        'num_palabras': row['num_palabras'],\n",
    "        'num_alfabeticos': row['num_alfabeticos'],\n",
    "        'num_numericos': row['num_numericos'],\n",
    "        'num_no_alfanum': row['num_no_alfanum'],\n",
    "        'num_divisas': row['num_divisas'],\n",
    "        'num_mayusculas': row['num_mayusculas'],\n",
    "        'num_exclamaciones': row['num_exclamaciones'],\n",
    "        'num_interrogaciones': row['num_interrogaciones'],\n",
    "        'num_urls': row['num_urls']\n",
    "    }\n",
    "\n",
    "    y = row['spam'] \n",
    "    y_pred = model_extreme.predict_one(x)\n",
    "    model_extreme.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "    eddm.update(int(y == y_pred))\n",
    "    ddm.update(int(y == y_pred))\n",
    "    kswin.update(int((x['num_mayusculas'])))\n",
    "    \n",
    "    if eddm.drift_detected: \n",
    "        print(f\"EDDM - Model drift detectado en el ejemplo {index} ({metric})\")\n",
    "    if ddm.drift_detected:\n",
    "        print(f\"DDM - Model drift detectado en el ejemplo {index} ({metric})\")\n",
    "    if kswin.drift_detected:\n",
    "        print(f\"KSWIN - Data drift detectado en el ejemplo {index} ({metric})\")\n",
    "\n",
    "print(f'Resultado final (ExtremelyFastDecisionTreeClassifier): {metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Agrupamiento y Detección de Anomalías**\n",
    "\n",
    "En esta sección, utilizamos el método no supervisado de KMeans para agrupar los datos en clústeres. Posteriormente, normalizamos los datos y detectamos las anomalías en función de la distancia euclidiana de cada dato al centroide de su clúster asignado.\n",
    "\n",
    "### Pasos:\n",
    "1. Normalizar los datos usando `StandardScaler`.\n",
    "2. Agrupar los datos usando `KMeans` con 5 clústeres.\n",
    "3. Calcular la distancia al centroide del clúster asignado para cada dato.\n",
    "4. Detectar anomalías si la distancia al centroide es mayor a un umbral definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import preprocessing, cluster\n",
    "import math\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "kmeans = cluster.KMeans(n_clusters=5, seed=10)\n",
    "\n",
    "threshold = 10.0\n",
    "\n",
    "anomalies_detected = 0\n",
    "\n",
    "def euclidean_distance(point, center):\n",
    "    return math.sqrt(sum((point[feature] - center[feature]) ** 2 for feature in point))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Flujo de Datos para Detección de Anomalías**\n",
    "\n",
    "En esta sección, simulamos el procesamiento en flujo continuo de datos (streaming) y escalamos las características y las agrupamos en clústeres utilizando KMeans. Detectaremos anomalías cuando la distancia al centroide sea mayor que el umbral definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalía detectada en 445 con distancia 10.19 \n",
      "Anomalía detectada en 793 con distancia 13.29 \n",
      "Anomalía detectada en 1085 con distancia 25.62 \n",
      "Anomalía detectada en 1579 con distancia 10.47 \n",
      "Anomalía detectada en 2158 con distancia 11.74 \n",
      "Anomalía detectada en 2503 con distancia 19.65 \n",
      "Anomalía detectada en 2676 con distancia 14.59 \n",
      "Anomalía detectada en 2791 con distancia 10.40 \n",
      "Anomalía detectada en 2849 con distancia 10.41 \n",
      "Anomalía detectada en 3564 con distancia 10.27 \n",
      "Anomalía detectada en 5019 con distancia 10.54 \n",
      "Anomalía detectada en 5083 con distancia 10.15 \n",
      "Anomalía detectada en 5106 con distancia 11.96 \n",
      "Anomalía detectada en 5266 con distancia 11.11 \n",
      "Anomalía detectada en 5542 con distancia 10.11 \n",
      "Total de anomalías detectadas: 15\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    features = {\n",
    "        'num_caracteres': float(row['num_caracteres']),\n",
    "        'num_palabras': float(row['num_palabras']),\n",
    "        'num_alfabeticos': float(row['num_alfabeticos']),\n",
    "        'num_numericos': float(row['num_numericos']),\n",
    "        'num_no_alfanum': float(row['num_no_alfanum']),\n",
    "        'num_divisas': float(row['num_divisas']),\n",
    "        'num_mayusculas': float(row['num_mayusculas']),\n",
    "        'num_exclamaciones': float(row['num_exclamaciones']),\n",
    "        'num_interrogaciones': float(row['num_interrogaciones']),\n",
    "        'num_urls': float(row['num_urls'])\n",
    "    }\n",
    "\n",
    "    scaler.learn_one(features)\n",
    "    \n",
    "    features_scaled = scaler.transform_one(features)\n",
    "\n",
    "    cluster_id = kmeans.predict_one(features_scaled)\n",
    "\n",
    "    centroids = kmeans.centers\n",
    "\n",
    "    if centroids:\n",
    "        centroid = centroids[cluster_id]\n",
    "\n",
    "        distance_to_centroid = euclidean_distance(features_scaled, centroid)\n",
    "\n",
    "        if distance_to_centroid > threshold:\n",
    "            anomalies_detected += 1\n",
    "            print(f\"Anomalía detectada en {index} con distancia {distance_to_centroid:.2f} \")\n",
    "\n",
    "    kmeans.learn_one(features_scaled)\n",
    "\n",
    "print(f\"Total de anomalías detectadas: {anomalies_detected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tratamiento de Texto**\n",
    "\n",
    "En esta sección, compararemos dos técnicas para la extracción de características de texto:\n",
    "- **Bag of Words (BOW)**: Simplemente cuenta las ocurrencias de cada palabra en el texto.\n",
    "- **TF-IDF (Term Frequency-Inverse Document Frequency)**: Pondera la frecuencia de las palabras considerando también su relevancia en el conjunto total de datos.\n",
    "\n",
    "Ambas técnicas serán combinadas con un clasificador Naive Bayes para evaluar cuál de las dos consigue mejores resultados en la clasificación de mensajes SPAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bag of Words con Naive Bayes**\n",
    "\n",
    "En este apartado implementamos la técnica de Bag of Words junto con el clasificador Naive Bayes. Entrenaremos el modelo y evaluaremos su rendimiento usando la métrica **F1 Score**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score final con Bag of Words: 0.9002590673575129\n"
     ]
    }
   ],
   "source": [
    "from river import feature_extraction, naive_bayes, compose, metrics\n",
    "\n",
    "bow = feature_extraction.BagOfWords(lowercase=True)\n",
    "\n",
    "model_bayes = naive_bayes.MultinomialNB()\n",
    "\n",
    "pipeline_BowNb = compose.Pipeline(('vectorizer', bow), ('nb', model_bayes))\n",
    "\n",
    "metric = metrics.F1()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    y = row['spam']\n",
    "    \n",
    "    y_pred = pipeline_BowNb.predict_one(text)\n",
    "    \n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "    pipeline_BowNb.learn_one(text, y)\n",
    "\n",
    "print(f\"F1 Score final con Bag of Words: {metric.get()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TF-IDF con Naive Bayes**\n",
    "\n",
    "En esta parte, utilizamos la técnica de TF-IDF junto con el clasificador Naive Bayes. Evaluaremos su rendimiento en flujo de datos de la misma manera que lo hicimos con Bag of Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score final con TF-IDF: 0.7392405063291139\n"
     ]
    }
   ],
   "source": [
    "tfidf = feature_extraction.TFIDF(lowercase=True, ngram_range=(1,1))\n",
    "model_bayes = naive_bayes.MultinomialNB()\n",
    "pipeline_TFIDFNb = compose.Pipeline(('vectorizer', tfidf), ('TFI-IDF', model_bayes))\n",
    "\n",
    "metric = metrics.F1()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    y = row['spam']\n",
    "    \n",
    "    y_pred = pipeline_TFIDFNb.predict_one(text)\n",
    "    \n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "    pipeline_TFIDFNb.learn_one(text, y)\n",
    "\n",
    "print(f\"F1 Score final con TF-IDF: {metric.get()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ensembles**\n",
    "Aplicamos el modelo AdaBoostingClassifier de la librería RIver sobre el clasificador que mejor resultado nos dio al inicio, el HOeffdingAdaptiveTreeClassifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score final: F1: 87.96%\n"
     ]
    }
   ],
   "source": [
    "from river import metrics, tree, ensemble\n",
    "\n",
    "metric = metrics.F1()\n",
    "model_adaptive = tree.HoeffdingAdaptiveTreeClassifier()\n",
    "model_ensemble_AdaBoost = ensemble.AdaBoostClassifier(model=model_adaptive, n_models=5)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "        'num_caracteres': row['num_caracteres'],\n",
    "        'num_palabras': row['num_palabras'],\n",
    "        'num_alfabeticos': row['num_alfabeticos'],\n",
    "        'num_numericos': row['num_numericos'],\n",
    "        'num_no_alfanum': row['num_no_alfanum'],\n",
    "        'num_divisas': row['num_divisas'],\n",
    "        'num_mayusculas': row['num_mayusculas'],\n",
    "        'num_exclamaciones': row['num_exclamaciones'],\n",
    "        'num_interrogaciones': row['num_interrogaciones'],\n",
    "        'num_urls': row['num_urls']\n",
    "    }\n",
    "\n",
    "    y = row['spam']\n",
    "    y_pred = model_ensemble_AdaBoost.predict_one(x)\n",
    "    model_ensemble_AdaBoost.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "\n",
    "print(f\"F1 Score final: {metric}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos el modelo ADWINBoostingClassifier de la librería RIver sobre el clasificador que mejor resultado nos dio al inicio, el HOeffdingAdaptiveTreeClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score final: F1: 87.48%\n"
     ]
    }
   ],
   "source": [
    "from river import metrics, tree, ensemble\n",
    "\n",
    "metric = metrics.F1()\n",
    "model_adaptive = tree.HoeffdingAdaptiveTreeClassifier()\n",
    "model_ensemble_AdWINBoosting = ensemble.ADWINBoostingClassifier(model=model_adaptive, n_models=5)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "        'num_caracteres': row['num_caracteres'],\n",
    "        'num_palabras': row['num_palabras'],\n",
    "        'num_alfabeticos': row['num_alfabeticos'],\n",
    "        'num_numericos': row['num_numericos'],\n",
    "        'num_no_alfanum': row['num_no_alfanum'],\n",
    "        'num_divisas': row['num_divisas'],\n",
    "        'num_mayusculas': row['num_mayusculas'],\n",
    "        'num_exclamaciones': row['num_exclamaciones'],\n",
    "        'num_interrogaciones': row['num_interrogaciones'],\n",
    "        'num_urls': row['num_urls']\n",
    "    }\n",
    "\n",
    "    y = row['spam']\n",
    "    y_pred = model_ensemble_AdWINBoosting.predict_one(x)\n",
    "    model_ensemble_AdWINBoosting.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "\n",
    "print(f\"F1 Score final: {metric}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Flujo de datos Simulado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos recibidos: {'text': 'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', 'num_caracteres': 111, 'num_palabras': 20, 'num_alfabeticos': 83, 'num_numericos': 0, 'num_no_alfanum': 28, 'num_divisas': 0, 'num_mayusculas': 3, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Ok lar... Joking wif u oni...', 'num_caracteres': 29, 'num_palabras': 6, 'num_alfabeticos': 18, 'num_numericos': 0, 'num_no_alfanum': 11, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", 'num_caracteres': 155, 'num_palabras': 28, 'num_alfabeticos': 97, 'num_numericos': 25, 'num_no_alfanum': 33, 'num_divisas': 0, 'num_mayusculas': 10, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 1\n",
      "Datos recibidos: {'text': 'U dun say so early hor... U c already then say...', 'num_caracteres': 49, 'num_palabras': 11, 'num_alfabeticos': 33, 'num_numericos': 0, 'num_no_alfanum': 16, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"Nah I don't think he goes to usf, he lives around here though\", 'num_caracteres': 61, 'num_palabras': 13, 'num_alfabeticos': 47, 'num_numericos': 0, 'num_no_alfanum': 14, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\", 'num_caracteres': 147, 'num_palabras': 32, 'num_alfabeticos': 103, 'num_numericos': 4, 'num_no_alfanum': 40, 'num_divisas': 1, 'num_mayusculas': 7, 'num_exclamaciones': 2, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 1\n",
      "Datos recibidos: {'text': 'Even my brother is not like to speak with me. They treat me like aids patent.', 'num_caracteres': 77, 'num_palabras': 16, 'num_alfabeticos': 60, 'num_numericos': 0, 'num_no_alfanum': 17, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\", 'num_caracteres': 160, 'num_palabras': 26, 'num_alfabeticos': 128, 'num_numericos': 1, 'num_no_alfanum': 31, 'num_divisas': 0, 'num_mayusculas': 10, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.', 'num_caracteres': 157, 'num_palabras': 26, 'num_alfabeticos': 106, 'num_numericos': 19, 'num_no_alfanum': 32, 'num_divisas': 1, 'num_mayusculas': 12, 'num_exclamaciones': 3, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 1\n",
      "Datos recibidos: {'text': 'Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030', 'num_caracteres': 154, 'num_palabras': 29, 'num_alfabeticos': 111, 'num_numericos': 13, 'num_no_alfanum': 30, 'num_divisas': 0, 'num_mayusculas': 14, 'num_exclamaciones': 1, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 1\n",
      "Proceso detenido por el usuario.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "try:\n",
    "    for index, row in df.iterrows():\n",
    "        X = {\n",
    "            'text': row['text'],\n",
    "            'num_caracteres': row['num_caracteres'],\n",
    "            'num_palabras': row['num_palabras'],\n",
    "            'num_alfabeticos': row['num_alfabeticos'],\n",
    "            'num_numericos': row['num_numericos'],\n",
    "            'num_no_alfanum': row['num_no_alfanum'],\n",
    "            'num_divisas': row['num_divisas'],\n",
    "            'num_mayusculas': row['num_mayusculas'],\n",
    "            'num_exclamaciones': row['num_exclamaciones'],\n",
    "            'num_interrogaciones': row['num_interrogaciones'],\n",
    "            'num_urls': row['num_urls']\n",
    "        }\n",
    "\n",
    "        y = row['spam'] \n",
    "        \n",
    "        print(f\"Datos recibidos: {X}, Etiqueta: {y}\")\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print('Proceso detenido por el usuario.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
