{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Práctica Flujos de Datos**\n",
    "- Detección de Concept Drift.\n",
    "- Clasificación.\n",
    "- Agrupamiento.\n",
    "- Tratamiento de Texto.\n",
    "- Ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import river\n",
    "from river import datasets\n",
    "from river import tree\n",
    "from river import metrics\n",
    "#from river import preprocessing\n",
    "from river import evaluate\n",
    "from river import drift\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Base de Datos**\n",
    "https://www.kaggle.com/datasets/mariumfaheem666/spam-sms-classification-using-nlp\n",
    "\n",
    "Se ha elegido un conjunto de datos utilizado para la detección de SPAM, en este la primera columna indica si el SMS recibido es SPAM o no y la siguiente contiene el texto del SMS. A partir de la segunda columna del texto, se han obtenido los siguientes atributos: el número de caracteres del SMS, el número de palabras, número de caracteres alfanuméricos, número de caracteres no alfanuméricos, número de símbolos de divisas, número de mayúsculas, de exclamaciones, de interrogaciones y de urls en cada mensaje. Estas características se han elegido ya que a nuestro parecer son importantes a la hora de decidir si un SMS es SPAM o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['spam', 'text', 'num_caracteres', 'num_palabras', 'num_alfabeticos',\n",
       "       'num_numericos', 'num_no_alfanum', 'num_divisas', 'num_mayusculas',\n",
       "       'num_exclamaciones', 'num_interrogaciones', 'num_urls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga de Datos\n",
    "df = pd.read_csv('spam_SMS_ampliado.csv')\n",
    "df.head(5)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de un Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive F1: F1: 86.65%\n"
     ]
    }
   ],
   "source": [
    "# crear, entrenar y evaluar modelo\n",
    "model_standard = tree.HoeffdingTreeClassifier()\n",
    "model_adaptive = tree.HoeffdingAdaptiveTreeClassifier()\n",
    "model_extreme = tree.ExtremelyFastDecisionTreeClassifier()\n",
    "#metric = metrics.Accuracy()\n",
    "metric = metrics.F1()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "            #'text': row['text'],\n",
    "            'num_caracteres': row['num_caracteres'],\n",
    "            'num_palabras': row['num_palabras'],\n",
    "            'num_alfabeticos': row['num_alfabeticos'],\n",
    "            'num_numericos': row['num_numericos'],\n",
    "            'num_no_alfanum': row['num_no_alfanum'],\n",
    "            'num_divisas': row['num_divisas'],\n",
    "            'num_mayusculas': row['num_mayusculas'],\n",
    "            'num_exclamaciones': row['num_exclamaciones'],\n",
    "            'num_interrogaciones': row['num_interrogaciones'],\n",
    "            'num_urls': row['num_urls']\n",
    "        }\n",
    "\n",
    "    y = row['spam'] \n",
    "    y_pred = model_standard.predict_one(x)  # realiza una predicción\n",
    "    model_standard.learn_one(x, y)          # entrena el modelo con un ejemplo\n",
    "    metric.update(y, y_pred)       # actualiza la métrica\n",
    "     \n",
    "print('Standard', metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive F1: 87.09%\n"
     ]
    }
   ],
   "source": [
    "# crear, entrenar y evaluar modelo\n",
    "model_adaptive = tree.HoeffdingAdaptiveTreeClassifier()\n",
    "#metric = metrics.Accuracy()\n",
    "metric = metrics.F1()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "            'num_caracteres': row['num_caracteres'],\n",
    "            'num_palabras': row['num_palabras'],\n",
    "            'num_alfabeticos': row['num_alfabeticos'],\n",
    "            'num_numericos': row['num_numericos'],\n",
    "            'num_no_alfanum': row['num_no_alfanum'],\n",
    "            'num_divisas': row['num_divisas'],\n",
    "            'num_mayusculas': row['num_mayusculas'],\n",
    "            'num_exclamaciones': row['num_exclamaciones'],\n",
    "            'num_interrogaciones': row['num_interrogaciones'],\n",
    "            'num_urls': row['num_urls']\n",
    "        }\n",
    "\n",
    "    y = row['spam'] \n",
    "    y_pred = model_adaptive.predict_one(x)  # realiza una predicción\n",
    "    model_adaptive.learn_one(x, y)          # entrena el modelo con un ejemplo\n",
    "    metric.update(y, y_pred)       # actualiza la métrica\n",
    "     \n",
    "print('Adaptive', metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'merit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m     y \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspam\u001b[39m\u001b[38;5;124m'\u001b[39m] \n\u001b[0;32m     21\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model_extreme\u001b[38;5;241m.\u001b[39mpredict_one(x)  \u001b[38;5;66;03m# realiza una predicción\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     \u001b[43mmodel_extreme\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m          \u001b[38;5;66;03m# entrena el modelo con un ejemplo\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     metric\u001b[38;5;241m.\u001b[39mupdate(y, y_pred)       \u001b[38;5;66;03m# actualiza la métrica\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdaptive\u001b[39m\u001b[38;5;124m'\u001b[39m, metric)\n",
      "File \u001b[1;32mc:\\Users\\alvar\\anaconda3\\Lib\\site-packages\\river\\tree\\extremely_fast_decision_tree.py:224\u001b[0m, in \u001b[0;36mExtremelyFastDecisionTreeClassifier.learn_one\u001b[1;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sort_to_leaf(x, y, sample_weight)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;66;03m# Process all nodes, starting from root to the leaf where the instance x belongs.\u001b[39;00m\n\u001b[1;32m--> 224\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\anaconda3\\Lib\\site-packages\\river\\tree\\extremely_fast_decision_tree.py:323\u001b[0m, in \u001b[0;36mExtremelyFastDecisionTreeClassifier._process_nodes\u001b[1;34m(self, x, y, sample_weight, node, parent, branch_index)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    322\u001b[0m             child_index, child \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mmost_common_path()\n\u001b[1;32m--> 323\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_growth_allowed \u001b[38;5;129;01mand\u001b[39;00m node\u001b[38;5;241m.\u001b[39mis_active():\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node\u001b[38;5;241m.\u001b[39mdepth \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth:  \u001b[38;5;66;03m# Max depth reached\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\anaconda3\\Lib\\site-packages\\river\\tree\\extremely_fast_decision_tree.py:323\u001b[0m, in \u001b[0;36mExtremelyFastDecisionTreeClassifier._process_nodes\u001b[1;34m(self, x, y, sample_weight, node, parent, branch_index)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    322\u001b[0m             child_index, child \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mmost_common_path()\n\u001b[1;32m--> 323\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_growth_allowed \u001b[38;5;129;01mand\u001b[39;00m node\u001b[38;5;241m.\u001b[39mis_active():\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node\u001b[38;5;241m.\u001b[39mdepth \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth:  \u001b[38;5;66;03m# Max depth reached\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\anaconda3\\Lib\\site-packages\\river\\tree\\extremely_fast_decision_tree.py:306\u001b[0m, in \u001b[0;36mExtremelyFastDecisionTreeClassifier._process_nodes\u001b[1;34m(self, x, y, sample_weight, node, parent, branch_index)\u001b[0m\n\u001b[0;32m    302\u001b[0m stop_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (new_weight \u001b[38;5;241m-\u001b[39m old_weight) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_reevaluate:\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;66;03m# Reevaluate the best split\u001b[39;00m\n\u001b[1;32m--> 306\u001b[0m     stop_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reevaluate_best_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbranch_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# The attribute observer template that will be replicated to new leaves\u001b[39;49;00m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Existing attribute observers that will be leveraged\u001b[39;49;00m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplitters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stop_flag:\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;66;03m# Move in depth\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\alvar\\anaconda3\\Lib\\site-packages\\river\\tree\\extremely_fast_decision_tree.py:434\u001b[0m, in \u001b[0;36mExtremelyFastDecisionTreeClassifier._reevaluate_best_split\u001b[1;34m(self, node, parent, branch_index, **kwargs)\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;66;03m# Manage memory\u001b[39;00m\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enforce_size_limit()\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m--> 434\u001b[0m     x_best\u001b[38;5;241m.\u001b[39mmerit \u001b[38;5;241m-\u001b[39m \u001b[43mx_current\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerit\u001b[49m \u001b[38;5;241m>\u001b[39m hoeffding_bound \u001b[38;5;129;01mor\u001b[39;00m hoeffding_bound \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtau\n\u001b[0;32m    435\u001b[0m ) \u001b[38;5;129;01mand\u001b[39;00m (id_current \u001b[38;5;241m!=\u001b[39m id_best):\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;66;03m# Create a new branch\u001b[39;00m\n\u001b[0;32m    437\u001b[0m     branch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_branch_selector(x_best\u001b[38;5;241m.\u001b[39mnumerical_feature, x_best\u001b[38;5;241m.\u001b[39mmultiway_split)\n\u001b[0;32m    438\u001b[0m     leaves \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m    439\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_leaf(initial_stats, parent\u001b[38;5;241m=\u001b[39mnode)\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m initial_stats \u001b[38;5;129;01min\u001b[39;00m x_best\u001b[38;5;241m.\u001b[39mchildren_stats\n\u001b[0;32m    441\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'merit'"
     ]
    }
   ],
   "source": [
    "# crear, entrenar y evaluar modelo\n",
    "model_extreme = tree.ExtremelyFastDecisionTreeClassifier()\n",
    "#metric = metrics.Accuracy()\n",
    "metric = metrics.F1()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "            'num_caracteres': row['num_caracteres'],\n",
    "            'num_palabras': row['num_palabras'],\n",
    "            'num_alfabeticos': row['num_alfabeticos'],\n",
    "            'num_numericos': row['num_numericos'],\n",
    "            'num_no_alfanum': row['num_no_alfanum'],\n",
    "            'num_divisas': row['num_divisas'],\n",
    "            'num_mayusculas': row['num_mayusculas'],\n",
    "            'num_exclamaciones': row['num_exclamaciones'],\n",
    "            'num_interrogaciones': row['num_interrogaciones'],\n",
    "            'num_urls': row['num_urls']\n",
    "        }\n",
    "\n",
    "    y = row['spam'] \n",
    "    y_pred = model_extreme.predict_one(x)  # realiza una predicción\n",
    "    model_extreme.learn_one(x, y)          # entrena el modelo con un ejemplo\n",
    "    metric.update(y, y_pred)       # actualiza la métrica\n",
    "     \n",
    "print('Adaptive', metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos recibidos: {'text': 'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', 'num_caracteres': 111, 'num_palabras': 20, 'num_alfabeticos': 83, 'num_numericos': 0, 'num_no_alfanum': 28, 'num_divisas': 0, 'num_mayusculas': 3, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'Ok lar... Joking wif u oni...', 'num_caracteres': 29, 'num_palabras': 6, 'num_alfabeticos': 18, 'num_numericos': 0, 'num_no_alfanum': 11, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", 'num_caracteres': 155, 'num_palabras': 28, 'num_alfabeticos': 97, 'num_numericos': 25, 'num_no_alfanum': 33, 'num_divisas': 0, 'num_mayusculas': 10, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 1\n",
      "Datos recibidos: {'text': 'U dun say so early hor... U c already then say...', 'num_caracteres': 49, 'num_palabras': 11, 'num_alfabeticos': 33, 'num_numericos': 0, 'num_no_alfanum': 16, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"Nah I don't think he goes to usf, he lives around here though\", 'num_caracteres': 61, 'num_palabras': 13, 'num_alfabeticos': 47, 'num_numericos': 0, 'num_no_alfanum': 14, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\", 'num_caracteres': 147, 'num_palabras': 32, 'num_alfabeticos': 103, 'num_numericos': 4, 'num_no_alfanum': 40, 'num_divisas': 1, 'num_mayusculas': 7, 'num_exclamaciones': 2, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 1\n",
      "Datos recibidos: {'text': 'Even my brother is not like to speak with me. They treat me like aids patent.', 'num_caracteres': 77, 'num_palabras': 16, 'num_alfabeticos': 60, 'num_numericos': 0, 'num_no_alfanum': 17, 'num_divisas': 0, 'num_mayusculas': 2, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': \"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\", 'num_caracteres': 160, 'num_palabras': 26, 'num_alfabeticos': 128, 'num_numericos': 1, 'num_no_alfanum': 31, 'num_divisas': 0, 'num_mayusculas': 10, 'num_exclamaciones': 0, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 0\n",
      "Datos recibidos: {'text': 'WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.', 'num_caracteres': 157, 'num_palabras': 26, 'num_alfabeticos': 106, 'num_numericos': 19, 'num_no_alfanum': 32, 'num_divisas': 1, 'num_mayusculas': 12, 'num_exclamaciones': 3, 'num_interrogaciones': 0, 'num_urls': 0}, Etiqueta: 1\n",
      "Datos recibidos: {'text': 'Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030', 'num_caracteres': 154, 'num_palabras': 29, 'num_alfabeticos': 111, 'num_numericos': 13, 'num_no_alfanum': 30, 'num_divisas': 0, 'num_mayusculas': 14, 'num_exclamaciones': 1, 'num_interrogaciones': 1, 'num_urls': 0}, Etiqueta: 1\n",
      "Proceso detenido.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for index, row in df.iterrows():\n",
    "        # Extrae características (X) y etiqueta (y)\n",
    "        X = {\n",
    "            'text': row['text'],\n",
    "            'num_caracteres': row['num_caracteres'],\n",
    "            'num_palabras': row['num_palabras'],\n",
    "            'num_alfabeticos': row['num_alfabeticos'],\n",
    "            'num_numericos': row['num_numericos'],\n",
    "            'num_no_alfanum': row['num_no_alfanum'],\n",
    "            'num_divisas': row['num_divisas'],\n",
    "            'num_mayusculas': row['num_mayusculas'],\n",
    "            'num_exclamaciones': row['num_exclamaciones'],\n",
    "            'num_interrogaciones': row['num_interrogaciones'],\n",
    "            'num_urls': row['num_urls']\n",
    "        }\n",
    "\n",
    "        y = row['spam'] \n",
    "        \n",
    "        print(f\"Datos recibidos: {X}, Etiqueta: {y}\")\n",
    "        \n",
    "        # Aquí se aplicarían los algoritmos online\n",
    "    \n",
    "        time.sleep(0.5)  # Se espera medio segundo para simular el flujo de datos\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print('Proceso detenido.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
