{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Práctica: Flujos de Datos en Clasificación, Concept Drift, Agrupamiento, Anomalías, Texto y Ensembles**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Álvaro Alcalde Cid\n",
    "- Felipe Guzmán Rodríguez\n",
    "- Pablo Díaz-Masa Valencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conjunto de datos**\n",
    "\n",
    "Este dataset proviene de Kaggle. En principio, sólo contenía dos campos: el texto de un SMS y una variable binaria que indica si es spam o no.\n",
    "Hemos añadido diez variables más a partir del texto de cada mensaje. Mediante expresiones regulares, hemos contado características numéricas relevantes del mensaje y las hemos incluido para tareas posteriores.\n",
    "    \n",
    "Este conjunto de datos contiene 5574 registros y 12 columnas:\n",
    "\n",
    "- spam: Etiqueta que indica si el mensaje es spam (1) o no (0)\n",
    "- text: El contenido del mensaje de texto\n",
    "- num_caracteres: Número total de caracteres en el mensaje\n",
    "- num_palabras: Cantidad de palabras\n",
    "- num_alfabeticos: Número de caracteres alfabéticos\n",
    "- num_numericos: Número de caracteres numéricos\n",
    "- num_no_alfanum: Cantidad de caracteres no alfanuméricos (%, &, #, $, ;, etc.)\n",
    "- num_divisas: Número de símbolos de divisas ($, €, £, etc.)\n",
    "- num_mayusculas: Número de caracteres en mayúscula\n",
    "- num_exclamaciones: Número de signos de exclamación\n",
    "- num_interrogaciones: Número de signos de interrogación\n",
    "- num_urls: Cantidad de URLs presentes en el mensaje\n",
    "    \n",
    "Este conjunto de datos ofrece información útil y tiene la forma idónea para los objetivos de esta práctica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Carga de Datos**\n",
    "\n",
    "Cargamos el dataset que contiene los SMS con sus características extraídas y una columna que indica si es SPAM o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['spam', 'text', 'num_caracteres', 'num_palabras', 'num_alfabeticos',\n",
       "       'num_numericos', 'num_no_alfanum', 'num_divisas', 'num_mayusculas',\n",
       "       'num_exclamaciones', 'num_interrogaciones', 'num_urls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos\n",
    "df = pd.read_csv('spam_SMS_ampliado.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "      <th>num_caracteres</th>\n",
       "      <th>num_palabras</th>\n",
       "      <th>num_alfabeticos</th>\n",
       "      <th>num_numericos</th>\n",
       "      <th>num_no_alfanum</th>\n",
       "      <th>num_divisas</th>\n",
       "      <th>num_mayusculas</th>\n",
       "      <th>num_exclamaciones</th>\n",
       "      <th>num_interrogaciones</th>\n",
       "      <th>num_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>20</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>28</td>\n",
       "      <td>97</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spam                                               text  num_caracteres  \\\n",
       "0     0  Go until jurong point, crazy.. Available only ...             111   \n",
       "1     0                      Ok lar... Joking wif u oni...              29   \n",
       "2     1  Free entry in 2 a wkly comp to win FA Cup fina...             155   \n",
       "3     0  U dun say so early hor... U c already then say...              49   \n",
       "4     0  Nah I don't think he goes to usf, he lives aro...              61   \n",
       "\n",
       "   num_palabras  num_alfabeticos  num_numericos  num_no_alfanum  num_divisas  \\\n",
       "0            20               83              0              28            0   \n",
       "1             6               18              0              11            0   \n",
       "2            28               97             25              33            0   \n",
       "3            11               33              0              16            0   \n",
       "4            13               47              0              14            0   \n",
       "\n",
       "   num_mayusculas  num_exclamaciones  num_interrogaciones  num_urls  \n",
       "0               3                  0                    0         0  \n",
       "1               2                  0                    0         0  \n",
       "2              10                  0                    0         0  \n",
       "3               2                  0                    0         0  \n",
       "4               2                  0                    0         0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Clasificación**\n",
    "\n",
    "Vamos a entrenar y evaluar varios clasificadores en flujo de datos:\n",
    "\n",
    "- Árbol Hoeffding (HoeffdingTreeClassifier).\n",
    "- Árbol Adaptativo Hoeffding (HoeffdingAdaptiveTreeClassifier).\n",
    "- Árbol de Decisión Extremadamente Rápido (ExtremelyFastDecisionTreeClassifier).\n",
    "\n",
    "Estos modelos se basan en árboles de decisión, empleando el teorema de Hoeffding para tomar decisiones con una cantidad mínima de datos, lo que los hace eficientes en entornos de flujo continuo. Hemos seleccionado el HoeffdingTreeClassifier como modelo base, ya que se espera que funcione bien con un flujo de datos estable, permitiendo realizar clasificaciones precisas con un bajo coste computacional.\n",
    "\n",
    "El HoeffdingAdaptiveTreeClassifier, en cambio, tiene la capacidad de adaptarse a cambios en los patrones de datos (concept drift). A pesar de que creemos que nuestros datos son relativamente estables, es posible que se produzcan pequeñas variaciones con el tiempo. Por lo tanto, evaluar este clasificador nos permitirá comprobar si, efectivamente, su capacidad de adaptación mejora la precisión en caso de que surjan desviaciones sutiles.\n",
    "\n",
    "Finalmente, hemos decidido incluir el ExtremelyFastDecisionTreeClassifier para comparar su eficiencia y rendimiento frente a los otros modelos. Este clasificador optimiza la construcción del árbol, lo que puede resultar en tiempos de procesamiento más rápidos. Sin embargo, es importante evaluar si esta velocidad compromete la precisión en comparación con un modelo más estable.\n",
    "\n",
    "La métrica de evaluación que utilizaremos para cada modelo será la F1 Score, ya que nos interesa balancear la precisión y la sensibilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score para HoeffdingTreeClassifier: F1: 86.65%\n"
     ]
    }
   ],
   "source": [
    "from river import tree, metrics\n",
    "\n",
    "model_standard = tree.HoeffdingTreeClassifier()\n",
    "\n",
    "metric = metrics.F1()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "            'num_caracteres': row['num_caracteres'],\n",
    "            'num_palabras': row['num_palabras'],\n",
    "            'num_alfabeticos': row['num_alfabeticos'],\n",
    "            'num_numericos': row['num_numericos'],\n",
    "            'num_no_alfanum': row['num_no_alfanum'],\n",
    "            'num_divisas': row['num_divisas'],\n",
    "            'num_mayusculas': row['num_mayusculas'],\n",
    "            'num_exclamaciones': row['num_exclamaciones'],\n",
    "            'num_interrogaciones': row['num_interrogaciones'],\n",
    "            'num_urls': row['num_urls']\n",
    "        }\n",
    "\n",
    "    y = row['spam'] \n",
    "    y_pred = model_standard.predict_one(x)\n",
    "    model_standard.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "print(f'F1 Score para HoeffdingTreeClassifier: {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score para HoeffdingAdaptiveTreeClassifier: F1: 86.97%\n"
     ]
    }
   ],
   "source": [
    "model_adaptive = tree.HoeffdingAdaptiveTreeClassifier()\n",
    "\n",
    "metric = metrics.F1()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "            'num_caracteres': row['num_caracteres'],\n",
    "            'num_palabras': row['num_palabras'],\n",
    "            'num_alfabeticos': row['num_alfabeticos'],\n",
    "            'num_numericos': row['num_numericos'],\n",
    "            'num_no_alfanum': row['num_no_alfanum'],\n",
    "            'num_divisas': row['num_divisas'],\n",
    "            'num_mayusculas': row['num_mayusculas'],\n",
    "            'num_exclamaciones': row['num_exclamaciones'],\n",
    "            'num_interrogaciones': row['num_interrogaciones'],\n",
    "            'num_urls': row['num_urls']\n",
    "        }\n",
    "\n",
    "    y = row['spam'] \n",
    "    y_pred = model_adaptive.predict_one(x)\n",
    "    model_adaptive.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "print(f'F1 Score para HoeffdingAdaptiveTreeClassifier: {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score para ExtremelyFastDecisionTreeClassifier: F1: 86.16%\n"
     ]
    }
   ],
   "source": [
    "model_extreme = tree.ExtremelyFastDecisionTreeClassifier(grace_period=120)\n",
    "\n",
    "metric = metrics.F1()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "            'num_caracteres': row['num_caracteres'],\n",
    "            'num_palabras': row['num_palabras'],\n",
    "            'num_alfabeticos': row['num_alfabeticos'],\n",
    "            'num_numericos': row['num_numericos'],\n",
    "            'num_no_alfanum': row['num_no_alfanum'],\n",
    "            'num_divisas': row['num_divisas'],\n",
    "            'num_mayusculas': row['num_mayusculas'],\n",
    "            'num_exclamaciones': row['num_exclamaciones'],\n",
    "            'num_interrogaciones': row['num_interrogaciones'],\n",
    "            'num_urls': row['num_urls']\n",
    "        }\n",
    "    \n",
    "    y = row['spam'] \n",
    "    y_pred = model_extreme.predict_one(x)\n",
    "    model_extreme.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "\n",
    "print(f'F1 Score para ExtremelyFastDecisionTreeClassifier: {metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Observaciones:**\n",
    "Las conclusiones obtenidas a partir de las pruebas con los clasificadores online muestran resultados consistentes con lo esperado. El ExtremelyFastDecisionTreeClassifier obtuvo un F1-Score de 86.16%, ligeramente inferior a los otros modelos. Esta pequeña disminución indica que, aunque este clasificador está optimizado para mayor velocidad, la precisión se ve mínimamente afectada. Aun así, debido a la leve diferencia, se podría considerar una opción adecuada en implementaciones en tiempo real, especialmente en contextos donde es fundamental una respuesta rápida, como es este, la detección de spam en SMS.\n",
    "\n",
    "Por otro lado, el HoeffdingAdaptiveTreeClassifier mostró un F1-Score ligeramente mejor en la mayoría de ejecuciones, superando al HoeffdingTreeClassifier por poco, que alcanzó un 86.65%. Esta mejora, aunque pequeña, demuestra que la capacidad del árbol adaptativo para ajustarse a cambios en los patrones de datos (concept drift) le permite obtener un rendimiento ligeramente superior. Esto lo convierte en una buena elección cuando existe la posibilidad de que las características del flujo de datos varíen.\n",
    "\n",
    "En resumen, las diferencias observadas en los resultados son mínimas, lo cual permite cierta flexibilidad a la hora de elegir el clasificador, dependiendo de si se prioriza la velocidad o la precisión en un entorno de flujo de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importancia de características**\n",
    "\n",
    "A continuación, aplicamos un modelo sencillo y sin optimizar parámetros para obtener información relevante acerca de la importancia de cada característica numérica. Para ello, entrenamos un xgboost para clasificación binaria y obtenemos la importancia de las características usando .feature_importances_, que devuelve un valor para cada característica que indica su capacidad para reducir la entropía, es decir, para separar los datos. A mayor importancia, más relevante será dicha característica para la clasificación. En esta tarea no utilizamos necesariamente técnicas flujos de datos, pues no son necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Score: 0.9387\n",
      "ROC AUC Score: 0.9939\n",
      "               Feature  Importance\n",
      "3        num_numericos    0.717752\n",
      "9             num_urls    0.101829\n",
      "6       num_mayusculas    0.034241\n",
      "5          num_divisas    0.032408\n",
      "4       num_no_alfanum    0.024511\n",
      "8  num_interrogaciones    0.022802\n",
      "7    num_exclamaciones    0.020581\n",
      "2      num_alfabeticos    0.018750\n",
      "1         num_palabras    0.016472\n",
      "0       num_caracteres    0.010654\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = df.drop(columns=['text', 'spam'])    # características numéricas\n",
    "y = df['spam']                           # variable objetivo\n",
    "\n",
    "model = xgb.XGBClassifier(eval_metric='logloss', random_state=133)   # xgboost default\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=133)     # cross validation\n",
    "\n",
    "f1 = make_scorer(f1_score)   # usamos F1, que es más robusta\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=cv, scoring=f1)   # evaluamos\n",
    "\n",
    "y_prob = cross_val_predict(model, X, y, cv=5, method='predict_proba')[:, 1]  # probabilidades, para calcular ROC AUC\n",
    "roc_auc = roc_auc_score(y, y_prob)\n",
    "\n",
    "print(f'Average F1 Score: {scores.mean():.4f}')\n",
    "print(f'ROC AUC Score: {roc_auc:.4f}')\n",
    "\n",
    "\n",
    "# características más importantes\n",
    "\n",
    "model.fit(X, y)    # modelo con todos los datos (sin validación cruzada)\n",
    "\n",
    "# Obtener la importancia de las características\n",
    "importancia = model.feature_importances_\n",
    "\n",
    "# dataframe con las características y sus respectivas importancias\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': importancia\n",
    "})\n",
    "\n",
    "# ordenar las características por importancia\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df)   # resultados\n",
    "\n",
    "# gráfica de importancias\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Importancia')\n",
    "plt.title('Importancia de características')\n",
    "plt.gca().invert_yaxis()  # característica más importante más arriba\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Observaciones:**\n",
    "\n",
    "En primer lugar, vemos que incluso con un modelo predeterminado, es decir, sin optimización de parámetros, obtenemos un rendimiento relativamente alto (F1 de 0.9387). Esto es buena señal, pues indica que nuestras características numéricas realmente tienen capacidad predictiva en este dataset.\n",
    "\n",
    "Por otra parte, al graficar la importancia de cada característica, salta a la vista inmediatamente la variable num_numericos, que indica la cantidad de caracteres numéricos que hay en un SMS. Su alta importancia (~ 0.72) indica que esta variable es muy buena separando los datos, es decir, reduciendo la entropía en las separaciones de los árboles que conforman el modelo. Por tanto, es la variable más relevante para la clasificación. La siguiente más importante es num_urls (~ 0.10), que indica el número de URLs presentes en cada mensaje. Esto muestra su capacidad predictiva de la clase binaria spam. De hecho, empleando únicamente estas dos variables, el rendimiento del modelo sigue siendo muy alto (F1 de 0.9027). El resto de variables no tienen una importancia tan grande, aunque también son algo relevantes para la predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Detección de Concept Drift**\n",
    "\n",
    "Después de haber clasificado los datos y observar cómo el HoeffdingAdaptiveTreeClassifier se adapta eficazmente al concept drift, mejorando sus predicciones en comparación con el árbol estándar, procederemos a la detección de dicho concept drift. Para ello, utilizaremos distintos detectores que monitorean tanto cambios en los datos (data drift) como en el rendimiento del modelo (model drift):\n",
    "\n",
    "- **KSWIN (KSWIN)**: Un detector de cambios basado en ventanas deslizantes, que permite identificar cambios en la distribución de los datos en tiempo real.\n",
    "- **EDDM (EDDM)**: Un monitor que analiza la desviación en los errores esperados, especializado en detectar cambios graduales en la distribución.\n",
    "- **DDM (DDM)**: Un monitor que detecta desviaciones en los errores de detección, útil para identificar cambios repentinos en el flujo de datos.\n",
    "\n",
    "Aplicaremos estos detectores sobre los tres modelos iniciales:\n",
    "\n",
    "1. HoeffdingTreeClassifier\n",
    "2. HoeffdingAdaptiveTreeClassifier\n",
    "3. ExtremelyFastDecisionTreeClassifier\n",
    "\n",
    "El objetivo de probar estos detectores en los tres modelos es comparar la frecuencia de detección de cambios entre el modelo estándar y el extremadamente rápido frente al adaptativo. Anticipamos que el modelo adaptativo debería detectar menos cambios, ya que, al ajustarse continuamente durante la clasificación, se espera que mitigue la aparición de concept drift de forma proactiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Concept Drift en HoeffdingTreeClassifier**\n",
    "\n",
    "Entrenaremos un modelo estándar de árbol Hoeffding y usaremos los detectores de concept drift para evaluar si se detectan cambios en los datos durante el flujo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.2\n",
      "EDDM - Model drift detectado en el ejemplo 48 (F1: 14.29%)\n",
      "EDDM - Model drift detectado en el ejemplo 111 (F1: 16.00%)\n",
      "EDDM - Model drift detectado en el ejemplo 174 (F1: 53.57%)\n",
      "EDDM - Model drift detectado en el ejemplo 224 (F1: 52.46%)\n",
      "EDDM - Model drift detectado en el ejemplo 297 (F1: 59.26%)\n",
      "EDDM - Model drift detectado en el ejemplo 389 (F1: 68.47%)\n",
      "DDM - Model drift detectado en el ejemplo 440 (F1: 71.43%)\n",
      "EDDM - Model drift detectado en el ejemplo 478 (F1: 73.13%)\n",
      "EDDM - Model drift detectado en el ejemplo 557 (F1: 75.64%)\n",
      "KSWIN - Data drift detectado en el ejemplo 3314 (F1: 85.87%)\n",
      "KSWIN - Data drift detectado en el ejemplo 3494 (F1: 85.99%)\n",
      "---------------------------------------------------\n",
      "Resultado final (HoeffdingTreeClassifier): F1: 86.65%\n",
      "Total de drifts detectados por EDDM: 8\n",
      "Total de drifts detectados por DDM: 1\n",
      "Total de drifts detectados por KSWIN: 2\n"
     ]
    }
   ],
   "source": [
    "from river import tree, metrics, drift\n",
    "import river\n",
    "print(river.__version__)\n",
    "\n",
    "model_standard = tree.HoeffdingTreeClassifier()\n",
    "\n",
    "metric = metrics.F1()\n",
    "\n",
    "kswin = drift.KSWIN()\n",
    "eddm = drift.binary.EDDM()\n",
    "ddm = drift.binary.DDM()\n",
    "\n",
    "total_eddm = 0\n",
    "total_ddm = 0\n",
    "total_kswin = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "        'num_caracteres': row['num_caracteres'],\n",
    "        'num_palabras': row['num_palabras'],\n",
    "        'num_alfabeticos': row['num_alfabeticos'],\n",
    "        'num_numericos': row['num_numericos'],\n",
    "        'num_no_alfanum': row['num_no_alfanum'],\n",
    "        'num_divisas': row['num_divisas'],\n",
    "        'num_mayusculas': row['num_mayusculas'],\n",
    "        'num_exclamaciones': row['num_exclamaciones'],\n",
    "        'num_interrogaciones': row['num_interrogaciones'],\n",
    "        'num_urls': row['num_urls']\n",
    "    }\n",
    "\n",
    "    y = row['spam'] \n",
    "    y_pred = model_standard.predict_one(x)\n",
    "    model_standard.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "    eddm.update(int(y == y_pred))\n",
    "    ddm.update(int(y == y_pred))\n",
    "    kswin.update(int((x['num_mayusculas'])))\n",
    "    \n",
    "    if eddm.drift_detected: \n",
    "        print(f\"EDDM - Model drift detectado en el ejemplo {index} ({metric})\")\n",
    "        total_eddm += 1\n",
    "    if ddm.drift_detected:\n",
    "        print(f\"DDM - Model drift detectado en el ejemplo {index} ({metric})\")\n",
    "        total_ddm += 1\n",
    "    if kswin.drift_detected:\n",
    "        print(f\"KSWIN - Data drift detectado en el ejemplo {index} ({metric})\")\n",
    "        total_kswin += 1\n",
    "\n",
    "print('---------------------------------------------------')\n",
    "print(f'Resultado final (HoeffdingTreeClassifier): {metric}')\n",
    "print(f'Total de drifts detectados por EDDM: {total_eddm}')\n",
    "print(f'Total de drifts detectados por DDM: {total_ddm}')\n",
    "print(f'Total de drifts detectados por KSWIN: {total_kswin}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Concept Drift en HoeffdingAdaptiveTreeClassifier**\n",
    "\n",
    "Ahora, vamos a implementar el árbol adaptativo Hoeffding, que puede adaptarse a los cambios detectados en el concepto de los datos, y lo evaluamos con los detectores de drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDDM - Model drift detectado en el ejemplo 46 (F1: 0.00%)\n",
      "EDDM - Model drift detectado en el ejemplo 90 (F1: 0.00%)\n",
      "EDDM - Model drift detectado en el ejemplo 197 (F1: 20.51%)\n",
      "EDDM - Model drift detectado en el ejemplo 336 (F1: 40.00%)\n",
      "EDDM - Model drift detectado en el ejemplo 405 (F1: 51.06%)\n",
      "EDDM - Model drift detectado en el ejemplo 474 (F1: 59.13%)\n",
      "EDDM - Model drift detectado en el ejemplo 563 (F1: 64.23%)\n",
      "DDM - Model drift detectado en el ejemplo 910 (F1: 78.03%)\n",
      "KSWIN - Data drift detectado en el ejemplo 933 (F1: 78.20%)\n",
      "KSWIN - Data drift detectado en el ejemplo 2468 (F1: 84.18%)\n",
      "KSWIN - Data drift detectado en el ejemplo 2872 (F1: 84.46%)\n",
      "KSWIN - Data drift detectado en el ejemplo 3313 (F1: 84.51%)\n",
      "KSWIN - Data drift detectado en el ejemplo 4053 (F1: 85.50%)\n",
      "---------------------------------------------------\n",
      "Resultado final (HoeffdingAdaptiveTreeClassifier): F1: 86.33%\n",
      "Total de drifts detectados por EDDM: 7\n",
      "Total de drifts detectados por DDM: 1\n",
      "Total de drifts detectados por KSWIN: 5\n"
     ]
    }
   ],
   "source": [
    "# crear, entrenar y evaluar modelo\n",
    "model_adaptive = tree.HoeffdingAdaptiveTreeClassifier()\n",
    "\n",
    "metric = metrics.F1()\n",
    "\n",
    "# detectores de drift\n",
    "kswin = drift.KSWIN()\n",
    "eddm = drift.binary.EDDM()\n",
    "ddm = drift.binary.DDM()\n",
    "\n",
    "total_eddm = 0\n",
    "total_ddm = 0\n",
    "total_kswin = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "        'num_caracteres': row['num_caracteres'],\n",
    "        'num_palabras': row['num_palabras'],\n",
    "        'num_alfabeticos': row['num_alfabeticos'],\n",
    "        'num_numericos': row['num_numericos'],\n",
    "        'num_no_alfanum': row['num_no_alfanum'],\n",
    "        'num_divisas': row['num_divisas'],\n",
    "        'num_mayusculas': row['num_mayusculas'],\n",
    "        'num_exclamaciones': row['num_exclamaciones'],\n",
    "        'num_interrogaciones': row['num_interrogaciones'],\n",
    "        'num_urls': row['num_urls']\n",
    "    }\n",
    "\n",
    "    y = row['spam'] \n",
    "    y_pred = model_adaptive.predict_one(x)\n",
    "    model_adaptive.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "    eddm.update(int(y == y_pred))\n",
    "    ddm.update(int(y == y_pred))\n",
    "    kswin.update(int((x['num_mayusculas'])))\n",
    "    \n",
    "    if eddm.drift_detected: \n",
    "        print(f\"EDDM - Model drift detectado en el ejemplo {index} ({metric})\")\n",
    "        total_eddm += 1\n",
    "    if ddm.drift_detected:\n",
    "        print(f\"DDM - Model drift detectado en el ejemplo {index} ({metric})\")\n",
    "        total_ddm += 1\n",
    "    if kswin.drift_detected:\n",
    "        print(f\"KSWIN - Data drift detectado en el ejemplo {index} ({metric})\")\n",
    "        total_kswin += 1\n",
    "\n",
    "print('---------------------------------------------------')\n",
    "print(f'Resultado final (HoeffdingAdaptiveTreeClassifier): {metric}')\n",
    "print(f'Total de drifts detectados por EDDM: {total_eddm}')\n",
    "print(f'Total de drifts detectados por DDM: {total_ddm}')\n",
    "print(f'Total de drifts detectados por KSWIN: {total_kswin}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Concept Drift en ExtremelyFastDecisionTreeClassifier**\n",
    "\n",
    "Finalmente, probamos el árbol de decisiones extremadamente rápido, junto con los detectores de drift.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDDM - Model drift detectado en el ejemplo 48 (F1: 14.29%)\n",
      "EDDM - Model drift detectado en el ejemplo 111 (F1: 16.00%)\n",
      "EDDM - Model drift detectado en el ejemplo 161 (F1: 50.00%)\n",
      "EDDM - Model drift detectado en el ejemplo 216 (F1: 53.57%)\n",
      "KSWIN - Data drift detectado en el ejemplo 381 (F1: 69.23%)\n",
      "DDM - Model drift detectado en el ejemplo 414 (F1: 69.64%)\n",
      "EDDM - Model drift detectado en el ejemplo 654 (F1: 79.14%)\n",
      "EDDM - Model drift detectado en el ejemplo 845 (F1: 82.17%)\n",
      "EDDM - Model drift detectado en el ejemplo 914 (F1: 83.10%)\n",
      "KSWIN - Data drift detectado en el ejemplo 1791 (F1: 83.56%)\n",
      "KSWIN - Data drift detectado en el ejemplo 2058 (F1: 83.76%)\n",
      "KSWIN - Data drift detectado en el ejemplo 2470 (F1: 84.45%)\n",
      "KSWIN - Data drift detectado en el ejemplo 3312 (F1: 85.05%)\n",
      "KSWIN - Data drift detectado en el ejemplo 3437 (F1: 85.22%)\n",
      "---------------------------------------------------\n",
      "Resultado final (ExtremelyFastDecisionTreeClassifier): F1: 86.16%\n",
      "Total de drifts detectados por EDDM: 7\n",
      "Total de drifts detectados por DDM: 1\n",
      "Total de drifts detectados por KSWIN: 6\n"
     ]
    }
   ],
   "source": [
    "# crear, entrenar y evaluar modelo\n",
    "model_extreme = tree.ExtremelyFastDecisionTreeClassifier(grace_period=120)\n",
    "metric = metrics.F1()\n",
    "\n",
    "# detectores de drift\n",
    "kswin = drift.KSWIN()\n",
    "eddm = drift.binary.EDDM()\n",
    "ddm = drift.binary.DDM()\n",
    "\n",
    "total_eddm = 0\n",
    "total_ddm = 0\n",
    "total_kswin = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "        'num_caracteres': row['num_caracteres'],\n",
    "        'num_palabras': row['num_palabras'],\n",
    "        'num_alfabeticos': row['num_alfabeticos'],\n",
    "        'num_numericos': row['num_numericos'],\n",
    "        'num_no_alfanum': row['num_no_alfanum'],\n",
    "        'num_divisas': row['num_divisas'],\n",
    "        'num_mayusculas': row['num_mayusculas'],\n",
    "        'num_exclamaciones': row['num_exclamaciones'],\n",
    "        'num_interrogaciones': row['num_interrogaciones'],\n",
    "        'num_urls': row['num_urls']\n",
    "    }\n",
    "\n",
    "    y = row['spam'] \n",
    "    y_pred = model_extreme.predict_one(x)\n",
    "    model_extreme.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "    eddm.update(int(y == y_pred))\n",
    "    ddm.update(int(y == y_pred))\n",
    "    kswin.update(int((x['num_mayusculas'])))\n",
    "\n",
    "    if eddm.drift_detected: \n",
    "        print(f\"EDDM - Model drift detectado en el ejemplo {index} ({metric})\")\n",
    "        total_eddm += 1\n",
    "    if ddm.drift_detected:\n",
    "        print(f\"DDM - Model drift detectado en el ejemplo {index} ({metric})\")\n",
    "        total_ddm += 1\n",
    "    if kswin.drift_detected:\n",
    "        print(f\"KSWIN - Data drift detectado en el ejemplo {index} ({metric})\")\n",
    "        total_kswin += 1\n",
    "\n",
    "\n",
    "print('---------------------------------------------------')\n",
    "print(f'Resultado final (ExtremelyFastDecisionTreeClassifier): {metric}')\n",
    "print(f'Total de drifts detectados por EDDM: {total_eddm}')\n",
    "print(f'Total de drifts detectados por DDM: {total_ddm}')\n",
    "print(f'Total de drifts detectados por KSWIN: {total_kswin}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Observaciones:**\n",
    "\n",
    "Como vemos, el EDDM es el que más cambios detecta, esto tiene sentido ya que el EDDM se encarga de detectar los cambios graduales, estos son cambios más ligeros que el EDDM al ser más sensible puede detectar. El DDM en cambio, es menos sensible a estos cambios ligeros y solo detecta cuando los cambios son más grandes. En los tres modelos se observa un solo DDM, esto indica que en los datos no hay cambios muy bruscos en general. El detector KSWIN ha detectado drifts al final del flujo de datos. Esto se debe a que KSWIN utiliza una ventana deslizante para monitorear cambios en la distribución de los datos. Al final del flujo, la ventana contiene suficientes datos recientes para identificar cambios significativos, lo que explica por qué los drifts se detectan en esta etapa.\n",
    "\n",
    "Los detectores de drift han identificado un número similar de cambios en los tres clasificadores. Esto indica que, aunque el HoeffdingAdaptiveTreeClassifier se adapta mejor a los cambios, los detectores de drift siguen siendo útiles para monitorear y detectar desviaciones en los datos.\n",
    "\n",
    "En general, se detectan pocos cambios en la distribución de los datos en este conjunto de datos y los pocos cambios que se detectan son ligeros, lo que nos indica que el EDDM es el más adecuado si lo que queremos es monitorizar estas pequeñas variaciones. Detectar estas variaciones en un conjunto de datos como este de dteección de spam en SMSs es muy importante ya que las estrategias de spam están constantemente cambiando, saber detectar estos cambios a tiempo y adaptar el modelo es muy importante para asegurarnos de que el modelo siga prediciendo con éxito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Agrupamiento y Detección de Anomalías**\n",
    "\n",
    "En esta sección, utilizamos el método no supervisado de KMeans para agrupar los datos en clústeres. Posteriormente, normalizamos los datos y detectamos las anomalías en función de la distancia euclidiana de cada dato al centroide de su clúster asignado.\n",
    "\n",
    "### Pasos:\n",
    "1. Normalizar los datos usando `StandardScaler`.\n",
    "2. Agrupar los datos usando `KMeans`.\n",
    "3. Calcular la distancia al centroide del clúster asignado para cada dato.\n",
    "4. Detectar anomalías si la distancia al centroide es mayor a un umbral definido.\n",
    "\n",
    "Nuestro objetivo es detectar mensajes que se desvían del comportamiento habitual, mensajes que son SPAM con características inusuales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selección del número de clusters\n",
    "\n",
    "Seleccionamos el número óptimo de clusters mediante el método del codo, que es una técnica visual que ayuda a encontrar el número ideal de clusters en algoritmos de clustering como k-means. La idea se basa en calcular la suma de las distancias al cuadrado dentro de cada cluster, conocida como WCSS (Within-Cluster Sum of Squares). \n",
    "\n",
    "Para encontrar el número adecuado de clusters, se entrena el modelo probando diferentes valores de k (cantidad de clusters) y, para cada uno, se calcula el WCSS. Este valor mide cómo de \"compactos\" están los puntos dentro de cada cluster, es decir, cómo de cerca están entre ellos y de su centro. Generalmente, el WCSS disminuye conforme k aumenta, ya que los puntos quedan más agrupados. Sin embargo, esta reducción en el WCSS es notable solo hasta cierto punto. Después de eso, la mejora se vuelve mínima. \n",
    "\n",
    "Al graficar el WCSS contra los valores de 𝑘, suele aparecer un cambio abrupto en la pendiente, formando una especie de \"codo\" en la gráfica, de donde proviene el nombre del método. Este punto de codo indica el número de clusters óptimo, ya que agregar más clusters después de este punto apenas mejora la compactación y puede llevar al modelo a un sobreajuste. Aunque este sistema puede ser subjetivo, es eficiente para elegir el número de clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from river import preprocessing, cluster\n",
    "import math\n",
    "\n",
    "# Lista para almacenar la inercia de cada valor de k\n",
    "wcss_values = []\n",
    "k_values = range(1, 21)  # Probar diferentes números de clusters, de 1 a 20\n",
    "\n",
    "# Scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# Para cada valor de k\n",
    "for k in k_values:\n",
    "    # Inicializar el modelo KMeans con el valor de k\n",
    "    kmeans = cluster.KMeans(n_clusters=k, seed=133)\n",
    "    wcss = 0.0  # Variable para acumular la inercia para este k\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        features = {\n",
    "            'num_caracteres': float(row['num_caracteres']),\n",
    "            'num_palabras': float(row['num_palabras']),\n",
    "            'num_alfabeticos': float(row['num_alfabeticos']),\n",
    "            'num_numericos': float(row['num_numericos']),\n",
    "            'num_no_alfanum': float(row['num_no_alfanum']),\n",
    "            'num_divisas': float(row['num_divisas']),\n",
    "            'num_mayusculas': float(row['num_mayusculas']),\n",
    "            'num_exclamaciones': float(row['num_exclamaciones']),\n",
    "            'num_interrogaciones': float(row['num_interrogaciones']),\n",
    "            'num_urls': float(row['num_urls'])\n",
    "        }\n",
    "\n",
    "        # Escalar las características\n",
    "        scaler.learn_one(features)\n",
    "        features_scaled = scaler.transform_one(features)\n",
    "\n",
    "        # Predecir el cluster y aprender en cada iteración\n",
    "        cluster_id = kmeans.predict_one(features_scaled)\n",
    "        kmeans.learn_one(features_scaled)\n",
    "\n",
    "        # Calcular la distancia cuadrada al centroide del cluster asignado\n",
    "        centroids = kmeans.centers\n",
    "        if centroids:\n",
    "            centroid = centroids[cluster_id]\n",
    "            distance_squared = sum((features_scaled[feature] - centroid[feature]) ** 2 for feature in features_scaled)\n",
    "            wcss += distance_squared\n",
    "\n",
    "    # Guardar la inercia para este valor de k\n",
    "    wcss_values.append(wcss)\n",
    "\n",
    "# Graficar el método del codo\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, wcss_values, marker='o')\n",
    "plt.xlabel('Número de clusters (k)')\n",
    "plt.ylabel('WCSS')\n",
    "plt.title('Método del codo para elegir el número óptimo de clusters')\n",
    "plt.xticks(range(int(min(k_values)), int(max(k_values)) + 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este método, no siempre queda totalmente claro qué cantidad de clusters seleccionar. Por ejemplo, en la gráfica generada hay dos puntos que podrían ser buenos candidatos: 4 y 7. Ambos son puntos donde el WCSS deja de descender tanto, aunque en este caso seleccionamos siete clusters, ya que la línea tiende a estabilizarse más después."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering con 7 clusters\n",
    "\n",
    "from river import preprocessing, cluster\n",
    "import math\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "kmeans = cluster.KMeans(n_clusters=7, seed=133)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Flujo de Datos para Detección de Anomalías**\n",
    "\n",
    "En esta sección, simulamos el procesamiento en flujo continuo de datos (streaming) y escalamos las características y las agrupamos en clústeres utilizando KMeans. Detectaremos anomalías cuando la distancia al centroide sea mayor que el umbral definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalía detectada en 445 con distancia 10.13 \n",
      "Anomalía detectada en 793 con distancia 12.54 \n",
      "Anomalía detectada en 1085 con distancia 25.62 \n",
      "Anomalía detectada en 1579 con distancia 10.47 \n",
      "Anomalía detectada en 2158 con distancia 11.74 \n",
      "Anomalía detectada en 2503 con distancia 19.08 \n",
      "Anomalía detectada en 2676 con distancia 12.20 \n",
      "Anomalía detectada en 2791 con distancia 10.40 \n",
      "Total de anomalías detectadas: 8\n",
      "----------------------------------------------\n",
      "Clúster 0: 317 datos\n",
      "Clúster 1: 126 datos\n",
      "Clúster 2: 2178 datos\n",
      "Clúster 3: 331 datos\n",
      "Clúster 4: 264 datos\n",
      "Clúster 5: 2013 datos\n",
      "Clúster 6: 345 datos\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "threshold = 10.0\n",
    "\n",
    "anomalies_detected = 0\n",
    "\n",
    "indices_anomalias = []\n",
    "\n",
    "cluster_counts = {}\n",
    "\n",
    "def euclidean_distance(point, center):\n",
    "    return math.sqrt(sum((point[feature] - center[feature]) ** 2 for feature in point))\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    features = {\n",
    "        'num_caracteres': float(row['num_caracteres']),\n",
    "        'num_palabras': float(row['num_palabras']),\n",
    "        'num_alfabeticos': float(row['num_alfabeticos']),\n",
    "        'num_numericos': float(row['num_numericos']),\n",
    "        'num_no_alfanum': float(row['num_no_alfanum']),\n",
    "        'num_divisas': float(row['num_divisas']),\n",
    "        'num_mayusculas': float(row['num_mayusculas']),\n",
    "        'num_exclamaciones': float(row['num_exclamaciones']),\n",
    "        'num_interrogaciones': float(row['num_interrogaciones']),\n",
    "        'num_urls': float(row['num_urls'])\n",
    "    }\n",
    "\n",
    "    scaler.learn_one(features)\n",
    "    \n",
    "    features_scaled = scaler.transform_one(features)\n",
    "\n",
    "    cluster_id = kmeans.predict_one(features_scaled)\n",
    "\n",
    "    centroids = kmeans.centers\n",
    "\n",
    "    if centroids:\n",
    "        centroid = centroids[cluster_id]\n",
    "\n",
    "        distance_to_centroid = euclidean_distance(features_scaled, centroid)\n",
    "\n",
    "        if distance_to_centroid > threshold:\n",
    "            anomalies_detected += 1\n",
    "            print(f\"Anomalía detectada en {index} con distancia {distance_to_centroid:.2f} \")\n",
    "            indices_anomalias.append(index)\n",
    "\n",
    "    kmeans.learn_one(features_scaled)\n",
    "\n",
    "    if cluster_id in cluster_counts:\n",
    "        cluster_counts[cluster_id] += 1\n",
    "    else:\n",
    "        cluster_counts[cluster_id] = 1\n",
    "\n",
    "print(f\"Total de anomalías detectadas: {anomalies_detected}\")\n",
    "print(\"----------------------------------------------\")\n",
    "\n",
    "# Print cluster counts\n",
    "for cluster_id, count in sorted(cluster_counts.items()):\n",
    "    print(f\"Clúster {cluster_id}: {count} datos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Observaciones**\n",
    "\n",
    "Al aplicar KMeans para agrupar nuestros datos después de normalizarlos, pudimos identificar mensajes que se salen de lo común. Básicamente, calculamos la distancia de cada punto al centroide de su clúster y si esa distancia supera un cierto umbral (que fijamos en 10.0), consideramos que es una anomalía.\n",
    "\n",
    "La normalización con StandardScaler fue clave aquí, ya que así nos aseguramos de que todas las características aporten por igual al cálculo de distancias. Si no lo hubiéramos hecho, algunas características podrían haber dominado el cálculo y las anomalías detectadas no serían representativas.\n",
    "\n",
    "A continuación mostramos las filas que han sido detectadas como anomalías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_alfabeticos</th>\n",
       "      <th>num_caracteres</th>\n",
       "      <th>num_divisas</th>\n",
       "      <th>num_exclamaciones</th>\n",
       "      <th>num_interrogaciones</th>\n",
       "      <th>num_mayusculas</th>\n",
       "      <th>num_no_alfanum</th>\n",
       "      <th>num_numericos</th>\n",
       "      <th>num_palabras</th>\n",
       "      <th>num_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>99</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>48</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>718</td>\n",
       "      <td>910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>354</td>\n",
       "      <td>611</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>253</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>403</td>\n",
       "      <td>588</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>183</td>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>230</td>\n",
       "      <td>306</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2676</th>\n",
       "      <td>85</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791</th>\n",
       "      <td>67</td>\n",
       "      <td>126</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_alfabeticos  num_caracteres  num_divisas  num_exclamaciones  \\\n",
       "445                99             121            0                  1   \n",
       "793                48              71            0                  9   \n",
       "1085              718             910            0                  0   \n",
       "1579              354             611            0                  0   \n",
       "2158              403             588            0                  5   \n",
       "2503              230             306            0                  1   \n",
       "2676               85             136            0                 11   \n",
       "2791               67             126            3                  0   \n",
       "\n",
       "      num_interrogaciones  num_mayusculas  num_no_alfanum  num_numericos  \\\n",
       "445                     2              99              22              0   \n",
       "793                     2              48              23              0   \n",
       "1085                    0              12             192              0   \n",
       "1579                    1              28             253              4   \n",
       "2158                    1              53             183              2   \n",
       "2503                   12              11              76              0   \n",
       "2676                    1               6              51              0   \n",
       "2791                    0              19              28             31   \n",
       "\n",
       "      num_palabras  num_urls  \n",
       "445             17         0  \n",
       "793             12         0  \n",
       "1085           171         0  \n",
       "1579           103         0  \n",
       "2158           125         0  \n",
       "2503            62         0  \n",
       "2676            30         0  \n",
       "2791            21         0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filas anómalas\n",
    "\n",
    "df.loc[indices_anomalias, df.columns.difference(['text', 'spam'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam                    0.134015\n",
       "num_caracteres         80.445282\n",
       "num_palabras           15.591676\n",
       "num_alfabeticos        59.114460\n",
       "num_numericos           2.383387\n",
       "num_no_alfanum         18.947435\n",
       "num_divisas             0.063150\n",
       "num_mayusculas          5.631324\n",
       "num_exclamaciones       0.250628\n",
       "num_interrogaciones     0.278615\n",
       "num_urls                0.019017\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Medias de cada columna en el dataset original\n",
    "\n",
    "df.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La observación más anómala es la 1085, que está a 25.62 unidades de distancia de su centroide. Esta fila se caracteriza por tener un elevadísimo número de caracteres, pues tiene 910 de ellos cuando la media del dataset es 80. Lo mismo ocurre con el número de palabras y el de caracteres alfabéticos.\n",
    "\n",
    "Después está la fila 2503, a 19.08 unidades de distancia de su centroide. También esta fila tiene un elevado número de caracteres, aunque el valor más dispar es el número de interrogaciones, 12, cuando la media de interrogaciones por mensaje es menor de uno. Algo similar ocurre con las filas 793 y 2158. La fila 2676, sin embargo, destaca por su cantidad de exclamaciones, 11, que también la hacen alejarse de otros elementos de su cluster.\n",
    "\n",
    "En conjunto, estas anomalías surgen al poseer en alguna variable un valor que dista mucho de los demás valores de esa variable. Por esto, al proyectar las observaciones en un espacio multidimensional, estos puntos se alejan significativamente más de sus respectivos centroides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tratamiento de Texto**\n",
    "\n",
    "En esta sección, compararemos dos técnicas para la extracción de características de texto:\n",
    "- **Bag of Words (BOW)**: Simplemente cuenta las ocurrencias de cada palabra en el texto.\n",
    "- **TF-IDF (Term Frequency-Inverse Document Frequency)**: Pondera la frecuencia de las palabras considerando también su relevancia en el conjunto total de datos.\n",
    "\n",
    "Ambas técnicas serán combinadas con un clasificador Naive Bayes para evaluar cuál de las dos consigue mejores resultados en la clasificación de mensajes SPAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bag of Words con Naive Bayes**\n",
    "\n",
    "En este apartado implementamos la técnica de Bag of Words junto con el clasificador Naive Bayes. Entrenaremos el modelo y evaluaremos su rendimiento usando la métrica **F1 Score**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score final con Bag of Words: 0.9002590673575129\n"
     ]
    }
   ],
   "source": [
    "from river import feature_extraction, naive_bayes, compose, metrics\n",
    "\n",
    "bow = feature_extraction.BagOfWords(lowercase=True)\n",
    "\n",
    "model_bayes = naive_bayes.MultinomialNB()\n",
    "\n",
    "pipeline_BowNb = compose.Pipeline(('vectorizer', bow), ('nb', model_bayes))\n",
    "\n",
    "metric = metrics.F1()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    y = row['spam']\n",
    "    \n",
    "    y_pred = pipeline_BowNb.predict_one(text)\n",
    "    \n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "    pipeline_BowNb.learn_one(text, y)\n",
    "\n",
    "print(f\"F1 Score final con Bag of Words: {metric.get()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TF-IDF con Naive Bayes**\n",
    "\n",
    "En esta parte, utilizamos la técnica de TF-IDF junto con el clasificador Naive Bayes. Evaluaremos su rendimiento en flujo de datos de la misma manera que lo hicimos con Bag of Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score final con TF-IDF: 0.7392405063291139\n"
     ]
    }
   ],
   "source": [
    "tfidf = feature_extraction.TFIDF(lowercase=True, ngram_range=(1,1))\n",
    "model_bayes = naive_bayes.MultinomialNB()\n",
    "pipeline_TFIDFNb = compose.Pipeline(('vectorizer', tfidf), ('TFI-IDF', model_bayes))\n",
    "\n",
    "metric = metrics.F1()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    y = row['spam']\n",
    "    \n",
    "    y_pred = pipeline_TFIDFNb.predict_one(text)\n",
    "    \n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "    pipeline_TFIDFNb.learn_one(text, y)\n",
    "\n",
    "print(f\"F1 Score final con TF-IDF: {metric.get()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Observaciones**\n",
    "\n",
    "Al comparar Bag of Words y TF-IDF con un clasificador Naive Bayes para detectar SPAM, observamos que Bag of Words obtuvo un F1 Score de 0.9003, mientras que TF-IDF alcanzó un F1 Score de 0.7392.\n",
    "\n",
    "Esto sugiere que, en nuestro caso, contar simplemente la frecuencia de las palabras es más efectivo que ponderarlas según su relevancia en el conjunto de datos. Bag of Words logró identificar mejor los mensajes de SPAM, posiblemente porque las palabras clave aparecen con mucha frecuencia en estos mensajes y no es necesario ajustar su peso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ensembles**\n",
    "\n",
    "Vamos a probar dos modelos diferentes de boosting, ya que creemos que al combinar múltiples árboles la precisión irá mejorando, sobre todo al poder centrarse en los datos mal predichos para corregirlos durante el entrenamiento. Vamos a aplicar los dos algoritmos de boosting, AdaBoost y ADWINBoost sobre el clasificador que mejor se adapta en nuestro caso, el HoeffdingAdaptiveTreeClassifier.\n",
    "\n",
    "### **AdaBoost**\n",
    "\n",
    "AdaBoost, o Adaptive Boosting, es un algoritmo de boosting que se usa para mejorar la precisión de predicciones al combinar varios modelos débiles en uno más robusto. AdaBoost, en lugar de otorgar la misma importancia a todas las observaciones desde el inicio, ajusta el enfoque en función de los errores. Al comienzo, asigna un peso igual a cada observación; sin embargo, a medida que avanza, incrementa el peso de las muestras que se han clasificado incorrectamente. Esto le permite al algoritmo enfocarse en los datos peor predichos e intentar captar esas diferencias. En cada nueva iteración, AdaBoost va acumulando los resultados de cada clasificador débil, lo que ayuda a mejorar el rendimiento del modelo en general.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score final: F1: 87.35%\n"
     ]
    }
   ],
   "source": [
    "from river import metrics, tree, ensemble\n",
    "\n",
    "metric = metrics.F1()\n",
    "model_adaptive = tree.HoeffdingAdaptiveTreeClassifier()\n",
    "model_ensemble_AdaBoost = ensemble.AdaBoostClassifier(model=model_adaptive, n_models=5)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "        'num_caracteres': row['num_caracteres'],\n",
    "        'num_palabras': row['num_palabras'],\n",
    "        'num_alfabeticos': row['num_alfabeticos'],\n",
    "        'num_numericos': row['num_numericos'],\n",
    "        'num_no_alfanum': row['num_no_alfanum'],\n",
    "        'num_divisas': row['num_divisas'],\n",
    "        'num_mayusculas': row['num_mayusculas'],\n",
    "        'num_exclamaciones': row['num_exclamaciones'],\n",
    "        'num_interrogaciones': row['num_interrogaciones'],\n",
    "        'num_urls': row['num_urls']\n",
    "    }\n",
    "\n",
    "    y = row['spam']\n",
    "    y_pred = model_ensemble_AdaBoost.predict_one(x)\n",
    "    model_ensemble_AdaBoost.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "\n",
    "print(f\"F1 Score final: {metric}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ADWINBoost**\n",
    "ADWINBoosting, o Adaptive Windowing, es una variante de los métodos de boosting diseñada específicamente para adaptarse a entornos de flujo de datos, es decir, situaciones en las que los datos se generan de manera continua y pueden cambiar con el tiempo, causando concept drift. Esta técnica ajusta automáticamente el tamaño de la ventana de datos utilizada para el entrenamiento en función de la detección de cambios en la distribución de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score final: F1: 86.08%\n"
     ]
    }
   ],
   "source": [
    "from river import metrics, tree, ensemble\n",
    "\n",
    "metric = metrics.F1()\n",
    "model_adaptive = tree.HoeffdingAdaptiveTreeClassifier()\n",
    "model_ensemble_AdWINBoosting = ensemble.ADWINBoostingClassifier(model=model_adaptive, n_models=5)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x = {\n",
    "        'num_caracteres': row['num_caracteres'],\n",
    "        'num_palabras': row['num_palabras'],\n",
    "        'num_alfabeticos': row['num_alfabeticos'],\n",
    "        'num_numericos': row['num_numericos'],\n",
    "        'num_no_alfanum': row['num_no_alfanum'],\n",
    "        'num_divisas': row['num_divisas'],\n",
    "        'num_mayusculas': row['num_mayusculas'],\n",
    "        'num_exclamaciones': row['num_exclamaciones'],\n",
    "        'num_interrogaciones': row['num_interrogaciones'],\n",
    "        'num_urls': row['num_urls']\n",
    "    }\n",
    "\n",
    "    y = row['spam']\n",
    "    y_pred = model_ensemble_AdWINBoosting.predict_one(x)\n",
    "    model_ensemble_AdWINBoosting.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "\n",
    "print(f\"F1 Score final: {metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Observaciones**\n",
    "Tras evaluar el rendimiento de los modelos AdaBoost y ADWINBoost, observamos que ADWINBoost ofrece resultados ligeramente superiores, lo cual coincide con nuestras expectativas, dado que ADWINBoost está diseñado específicamente para flujos de datos. Este modelo aprovecha ADWIN para detectar y adaptarse dinámicamente a las variaciones en los datos, incluyendo el data drift. Así, ADWINBoost logra corregir errores de manera más efectiva al ajustar el modelo continuamente, capturando mejor los cambios en la distribución de los datos y optimizando la clasificación de manera más precisa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
